[
    {
        "unique_identifier": "99840001",
        "description": [
            {
                "field_data": "A publicly accessible BigQuery dataset can potentially expose sensitive data to attackers who could gain unauthorized access to it. This can lead to a major business loss for the organization.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the BigQuery dataset being accessible to only those users that have explicitly given permission to access them through an IAM role.",
                "field_type": "impact"
            },
            {
                "field_data": "A BigQuery dataset with an IAM policy set to allUsers (anyone over the internet) and allAuthenticatedUsers (anyone logged in over a google service) is considered to be publicly accessible. This means that users which don't belong to the parent organization can gain access to the resource, which can lead to loss of data. Hence, it is recommended that BigQuery dataset should not be publicly accessible.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1530"
        ]
    },
    {
        "unique_identifier": "99840153",
        "description": [
            {
                "field_data": "Not making use of a CMEK prevents the client from having increased control over the behaviour of the encryption process, for example- the rotation policy of the encryption keys.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control results in the encryption of assets with customer managed keys as opposed to Google's default encryption-at-rest facility. This may result in an additional cost to the customer.",
                "field_type": "impact"
            },
            {
                "field_data": "CMEKs are customer managed keys that provide an extra layer of encryption over Google's standard data at rest encryption. The standard encryption is wrapped by the customer managed key, thus giving the customer more control over the encryption of the organization's data, since the customer gets to control the CMEK's rotation policy. Hence it is recommended that all BigQuery datasets are encrypted with CMEKs.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1530"
        ]
    },
    {
        "unique_identifier": "99840002",
        "description": [
            {
                "field_data": "Not enforcing SSL means the SQL instance may accept communication with unencrypted messages. This increases the vulnerability of the SQL instance data in transit during communication.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will result in SSL only communication being enforced on the remediated SQL instance.",
                "field_type": "impact"
            },
            {
                "field_data": "SSL communication is essential in order to protect data in transit. Encrypted communication with SQL instances should be enforced for all clients. Hence, it is recommended that all SQL instances enforce SSL only communications.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1557"
        ]
    },
    {
        "unique_identifier": "99840003",
        "description": [
            {
                "field_data": "A publicly accessible SQL instance can potentially expose sensitive data to attackers who could try to gain unauthorized access to it. This can lead to a major business loss for the organization.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the remediated SQL instance becoming non-accessible publicly (i.e from any IP address), instead it will only be accessible from a selected authorized IP addresses.",
                "field_type": "impact"
            },
            {
                "field_data": "A publicly accessible SQL instance allows connections from any IP address. Meaning even unauthorized clients can attempt to make connections to the instance. This can lead to unauthorized access and subsequent data loss. Hence it is recommended that no Cloud SQL instances are made publicly accessible.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1596"
        ]
    },
    {
        "unique_identifier": "99840004",
        "description": [
            {
                "field_data": "Not enabling auto backup for SQL instances leaves them more vulnerable to loss of data through accidental or malicious deletion. It also adds an added cost of having to carry out periodic manual backups which is less efficient and also more prone to human error.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the enabling of automated backups for the remediated SQL instance.",
                "field_type": "impact"
            },
            {
                "field_data": "Auto backup for SQL instances protects against unexpected loss of data through accidental deletion or corruption of databases. It is an important feature from a business point of view while also circumventing the need for periodic manual backups. Hence it is recommended that all Cloud SQL instances have auto-backup enabled.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1485"
        ]
    },
    {
        "unique_identifier": "99840005",
        "description": [
            {
                "field_data": "Having a public IP address configured for an SQL instance makes it more vulnerable to potential unauthorized access. This could lead to a loss of sensitive data if the attackers manage to gain access to the instance.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the deletion of the SQL instance public IP address and it being replaced by a private internal IP address.",
                "field_type": "impact"
            },
            {
                "field_data": "Having a Cloud SQL instance with a public IP address increases the attack surface for the organization. Private IP addresses ensure better network security for the instance. Hence, it is recommended that no Cloud SQL instance has a public IP address.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1580"
        ]
    },
    {
        "unique_identifier": "99840006",
        "description": [
            {
                "field_data": "Not making use of a CMEKs prevents the client from having increased control over the behaviour of the encryption process, for example- the rotation policy of the encryption keys.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control results in the deletion of the unremediated instance and creation of a new instance which uses customer managed keys as opposed to Google's default encryption-at-rest facility. This may result in an additional cost to the customer.",
                "field_type": "impact"
            },
            {
                "field_data": "CMEK's allow for keys being used in SQL instances to be wrapped by keys provided by Cloud KMS- thus giving the resource owner more control over access to their data. Hence it is recommended that all Cloud SQL instances are encrypted with CMEKs.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1596"
        ]
    },
    {
        "unique_identifier": "99840007",
        "description": [
            {
                "field_data": "Enabling contained database authentication gives users more authority than necessary to connect with and move databases out of the SQL Server in question. In case a user's credentials are compromised, the attackers can misuse these features to cause significant business losses for the organization.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will result in the disabling of the contained database authentication flag in the unremediated SQL instance.",
                "field_type": "impact"
            },
            {
                "field_data": "A contained database includes all database settings and metadata required to define the database. If enabled, users can connect to the database without authentication at the Database Engine level along with making it possible to move the database to another SQL Server instance which can cause a significant loss of data. Hence it is recommended that all SQL Server instances are configured to have \"contained database authentication\" database flag set to off.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1596"
        ]
    },
    {
        "unique_identifier": "99840008",
        "description": [
            {
                "field_data": "Enabling this flag can lead to exponentially greater loss of data if even one of the instances is compromised- as compared to when it is disabled. Thus, it could also lead to a proportionally great business loss for the organization.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will result in the disabling of the cross_db_ownership_chaining flag in the unremediated SQL instance.",
                "field_type": "impact"
            },
            {
                "field_data": "When the \"cross_db_ownership_chaining \" database flag is set to on for even one instance, it is automatically enabled on all the other instances. Hence it is recommended that \"cross_db_ownership_chaining \" database flag is set to off for all SQL Server instances.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1580"
        ]
    },
    {
        "unique_identifier": "99840009",
        "description": [
            {
                "field_data": "Enabling this flag can lead to certain security gaps that can expose vulnerabilities which when exploited can cause a loss of data related to the SQL instance.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will result in the disabling of the local_infile flag in the unremediated SQL instance.",
                "field_type": "impact"
            },
            {
                "field_data": "When the \"local_infile\" database flag is enabled, it allows the local execution of the load data statement for the MySQL instance. This can result in unwanted security gaps which when exploited can result in the loss of data. Hence, it is recommended that all MySQL instances are configured to have \"local_infile\" database flag set to off.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1552"
        ]
    },
    {
        "unique_identifier": "99840010",
        "description": [
            {
                "field_data": "Disabling this flag makes the early detection of suspicious activities more difficult, thereby increasing the potential business loss the organization could suffer from attacks.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will result in the enabling of the log_checkpoints flag in the unremediated SQL instance.",
                "field_type": "impact"
            },
            {
                "field_data": "When the \"log_checkpoints\" database flag is enabled, it results in the logging of checkpoints and restart points in the server logs. These logs contain useful information in their metadata -like the number of buffers and the time that was spent writing them. Hence it is recommended that all PostgreSQL instances are configured to have \"log_checkpoints\" database flag set to on.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1078"
        ]
    },
    {
        "unique_identifier": "99840011",
        "description": [
            {
                "field_data": "Disabling this flag makes the early detection of suspicious activities more difficult, thereby increasing the potential business loss the organization could suffer from attacks.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will result in the enabling of the log_connections flag in the unremediated SQL instance.",
                "field_type": "impact"
            },
            {
                "field_data": "When the \"log_connections\" database flag is enabled, it results in the logging of all connection attempts and successful connections made to the server. These logs contain useful information which can help differentiate unusual/suspicious connection attempts made to an instance when troubleshooting. Hence it is recommended that all PostgreSQL instances are configured to have \"log_connections\" database flag set to on.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1078"
        ]
    },
    {
        "unique_identifier": "99840012",
        "description": [
            {
                "field_data": "Disabling this flag makes the early detection of suspicious activities more difficult, thereby increasing the potential business loss the organization could suffer from attacks.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will result in the enabling of the log_disconnections flag in the unremediated SQL instance.",
                "field_type": "impact"
            },
            {
                "field_data": "When the \"log_disconnections\" database flag is enabled, it results in the logging of information related to a connection at the end of the session. These logs contain useful information which can help in troubleshooting issues and identifying suspicious activity over a given time period. Hence it is recommended that all PostgreSQL instances are configured to have \"log_disconnections\" database flag set to on.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1078"
        ]
    },
    {
        "unique_identifier": "99840013",
        "description": [
            {
                "field_data": "Disabling this flag makes the early detection of poor performance from SQL instances more difficult, thereby increasing the degree of potential disruption of services for the organization.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will result in the enabling of the log_lock_waits flag in the unremediated SQL instance.",
                "field_type": "impact"
            },
            {
                "field_data": "When the \"log_lock_wait\" database flag is enabled, it results in the logging of all session waits that take longer than the duration of a predefined deadlock_timeout to acquire a lock. These logs contain useful information which can help diagnose poor performance in an instance owing to lock waits. Hence it is recommended that all PostgreSQL instances are configured to have \"log_lock_wait\" database flag set to on.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1078"
        ]
    },
    {
        "unique_identifier": "99840014",
        "description": [
            {
                "field_data": "Enabling this flag results in the logging of potentially sensitive data related to SQL statements. If these logs are accessed by attackers, it could lead to a large business loss for the organization.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will result in the disabling of the log_min_duration_statement flag in the unremediated SQL instance.",
                "field_type": "impact"
            },
            {
                "field_data": "When the \"log_min_duration_statement\" database flag is set to -1, it results in the logging of all SQL statements that take more than a minimum specified time to execute. Since these SQL statements might contain sensitive information, logging them may lead to this information being compromised. Hence it is recommended that all PostgreSQL instances are configured to have \"log_min_duration_statement\" database flag set to -1.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1552"
        ]
    },
    {
        "unique_identifier": "99840015",
        "description": [
            {
                "field_data": "If this flag is not set appropriately, it could cause a business loss for the organization by storing more data than required, or on the other hand it could also lead to insufficient data being logged which could hinder the organization's capability to tackle certain crucial errors.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will result in the log_min_error flag being set to a value that appropriately captures the amount of logs needed for efficient monitoring in the unremediated SQL instance.",
                "field_type": "impact"
            },
            {
                "field_data": "The \"log_min_error_statement\" database flag records the minimum severity level that an errant SQL statement must clear for it to be logged as an error statement in the server logs. If the minimum severity is set too high, important errors may end up not being flagged. If its too low, it will lead to too many messages being logged thus making it harder to isolate the critical errors. Hence, it is recommended that all PostgreSQL instances are configured to have \"log_min_error_statement\" database flag set appropriately- according to the Organization's logging policy.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1596"
        ]
    },
    {
        "unique_identifier": "99840015",
        "description": [
            {
                "field_data": "If this flag is not set appropriately, it could cause a business loss for the organization by storing more data than required, or on the other hand it could also lead to insufficient data being logged which could hinder the organization's capability to tackle certain crucial errors.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will result in the log_min_error flag being set to a value that appropriately captures the amount of logs needed for efficient monitoring in the unremediated SQL instance.",
                "field_type": "impact"
            },
            {
                "field_data": "The \"log_min_error_statement\" database flag records the minimum severity level that an errant SQL statement must clear for it to be logged as an error statement in the server logs. If the minimum severity is set too high, important errors may end up not being flagged. If its too low, it will lead to too many messages being logged thus making it harder to isolate the critical errors. Hence, it is recommended that all PostgreSQL instances are configured to have \"log_min_error_statement\" database flag set appropriately- according to the Organization's logging policy.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1596"
        ]
    },
    {
        "unique_identifier": "99840017",
        "description": [
            {
                "field_data": "Not setting a root password for an SQL instance allows unchecked root-level access to any user that establishes a connection with the instance. This can compromise all the data being stored on the instance and severely affect any services using it- which can result in a significant business loss for the organization.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will result in a password being set on the root user of the unremediated SQL instance. Thus, only the users privy to the password will be able to gain root user privileges.",
                "field_type": "impact"
            },
            {
                "field_data": "By default the root account on a Cloud SQL instance does not have a password. It is imperative to protect the instance by setting a root account password in order to prevent unauthorized access to root privileged commands. Hence it is recommended that all Cloud SQL instances have a password configured for the root account.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1552"
        ]
    },
    {
        "unique_identifier": "99840018",
        "description": [
            {
                "field_data": "Not setting a strong root password for an SQL instance makes it more likely for an attacker to gain access to the root user having established a connection with the instance. This can compromise all the data being stored on the instance and severely affect any services using it- which can result in a significant business loss for the organization.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will result in a strong password being set on the root user of the unremediated SQL instance.",
                "field_type": "impact"
            },
            {
                "field_data": "The root account is a common target for attempts at unauthorized access since it exists on most Cloud SQL instances. This makes setting a strong root password an important deterrent to unauthorized access. Hence it is recommended that no Cloud SQL instance has a weak password configured for the root account.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1552"
        ]
    },
    {
        "unique_identifier": "99840021",
        "description": [
            {
                "field_data": "If the remediation of this control is not performed then it can adversely affect the security of the system and can cause data loss which could lead to business loss for the organization.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will result in the enabling of the \"external scripts\" flag in the unremediated PostgreSQL instance.",
                "field_type": "impact"
            },
            {
                "field_data": "When activated, this setting enables the execution of scripts with certain remote language extensions. Since this feature can adversely affect the security of the system. Hence it is recommended that all PostgreSQL instances are configured to have \"external scripts\" database flag set to off.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1552"
        ]
    },
    {
        "unique_identifier": "99840022",
        "description": [
            {
                "field_data": "If the remediation of this control is not performed then it will be tough/crucial in identifying slow queries and troubleshooting database issues and it could cause a business loss for the organization.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will result in the enabling of the log_duration flag in the unremediated SQL instance.",
                "field_type": "impact"
            },
            {
                "field_data": "When log_duration is enabled, this setting causes the execution time and duration of each completed statement to be logged. Monitoring the amount of time it takes to execute queries can be crucial in identifying slow queries and troubleshooting database issues. Hence it is recommended that all PostgreSQL instances are configured to have \" log_duration\" database flag set to on.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1596"
        ]
    },
    {
        "unique_identifier": "99840023",
        "description": [
            {
                "field_data": "If this flag is not set appropriately, it could cause a business loss for the organization by storing more data than required, or on the other hand it could also lead to insufficient data being logged which could hinder the organization's capability to tackle certain crucial errors.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will result in the log_error_verbosity flag being set to a value that appropriately captures the depth of details required in the logs needed for efficient monitoring in the unremediated SQL instance.",
                "field_type": "impact"
            },
            {
                "field_data": "The log_error_verbosity flag controls the amount of detail in messages logged. The greater the verbosity, the more details are recorded in messages. We recommend setting this flag to default or stricter.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1596"
        ]
    },
    {
        "unique_identifier": "99840025",
        "description": [
            {
                "field_data": "If this flag is not set appropriately, it could cause a business loss for the organization by storing more data than required, or on the other hand it could also lead to insufficient data being logged which could hinder the organization's capability to tackle certain crucial errors.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will result in the log_min_error_severity flag being set to a value that appropriately captures the amount of logs needed for efficient monitoring in the unremediated SQL instance.",
                "field_type": "impact"
            },
            {
                "field_data": "The log_min_error_statement flag controls whether SQL statements that cause error conditions are recorded in server logs. SQL statements of the specified severity or stricter are logged with messages for the error statements. The stricter the severity, the fewer messages are recorded. If log_min_error_statement is not set to the correct value, messages might not be classified as error messages. A severity set too low would increase the number of messages and make it difficult to find actual errors. A severity level that is too high (too strict) might cause error messages for actual errors to not be logged.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1596"
        ]
    },
    {
        "unique_identifier": "99840026",
        "description": [
            {
                "field_data": "If this flag is not set appropriately, it could cause a business loss for the organization by storing more data than required, or on the other hand it could also lead to insufficient data being logged which could hinder the organization's capability to tackle certain crucial errors.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will result in the log_min_messages flag being set to \"warning\".",
                "field_type": "impact"
            },
            {
                "field_data": "The log_min_messages flag controls which message levels are recorded in server logs. The higher the severity, the fewer messages are recorded. Hence it is recommended that all PostgreSQL instances are configured to have \" log_min_messages\" database flag set to warning.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1596"
        ]
    },
    {
        "unique_identifier": "99840026",
        "description": [
            {
                "field_data": "If this flag is not set appropriately, it could cause a business loss for the organization by storing more data than required, or on the other hand it could also lead to insufficient data being logged which could hinder the organization's capability to tackle certain crucial errors.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will result in the log_min_messages flag being set to \"warning\".",
                "field_type": "impact"
            },
            {
                "field_data": "The log_min_messages flag controls which message levels are recorded in server logs. The higher the severity, the fewer messages are recorded. Hence it is recommended that all PostgreSQL instances are configured to have \" log_min_messages\" database flag set to warning.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1596"
        ]
    },
    {
        "unique_identifier": "99840026",
        "description": [
            {
                "field_data": "If this flag is not set appropriately, it could cause a business loss for the organization by storing more data than required, or on the other hand it could also lead to insufficient data being logged which could hinder the organization's capability to tackle certain crucial errors.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will result in the log_min_messages flag being set to \"warning\".",
                "field_type": "impact"
            },
            {
                "field_data": "The log_min_messages flag controls which message levels are recorded in server logs. The higher the severity, the fewer messages are recorded. Hence it is recommended that all PostgreSQL instances are configured to have \" log_min_messages\" database flag set to warning.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1596"
        ]
    },
    {
        "unique_identifier": "99840026",
        "description": [
            {
                "field_data": "If this flag is not set appropriately, it could cause a business loss for the organization by storing more data than required, or on the other hand it could also lead to insufficient data being logged which could hinder the organization's capability to tackle certain crucial errors.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will result in the log_min_messages flag being set to \"warning\".",
                "field_type": "impact"
            },
            {
                "field_data": "The log_min_messages flag controls which message levels are recorded in server logs. The higher the severity, the fewer messages are recorded. Hence it is recommended that all PostgreSQL instances are configured to have \" log_min_messages\" database flag set to warning.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1596"
        ]
    },
    {
        "unique_identifier": "99840026",
        "description": [
            {
                "field_data": "If this flag is not set appropriately, it could cause a business loss for the organization by storing more data than required, or on the other hand it could also lead to insufficient data being logged which could hinder the organization's capability to tackle certain crucial errors.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will result in the log_min_messages flag being set to \"warning\".",
                "field_type": "impact"
            },
            {
                "field_data": "The log_min_messages flag controls which message levels are recorded in server logs. The higher the severity, the fewer messages are recorded. Hence it is recommended that all PostgreSQL instances are configured to have \" log_min_messages\" database flag set to warning.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1596"
        ]
    },
    {
        "unique_identifier": "99840026",
        "description": [
            {
                "field_data": "If this flag is not set appropriately, it could cause a business loss for the organization by storing more data than required, or on the other hand it could also lead to insufficient data being logged which could hinder the organization's capability to tackle certain crucial errors.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will result in the log_min_messages flag being set to \"warning\".",
                "field_type": "impact"
            },
            {
                "field_data": "The log_min_messages flag controls which message levels are recorded in server logs. The higher the severity, the fewer messages are recorded. Hence it is recommended that all PostgreSQL instances are configured to have \" log_min_messages\" database flag set to warning.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1596"
        ]
    },
    {
        "unique_identifier": "99840026",
        "description": [
            {
                "field_data": "If this flag is not set appropriately, it could cause a business loss for the organization by storing more data than required, or on the other hand it could also lead to insufficient data being logged which could hinder the organization's capability to tackle certain crucial errors.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will result in the log_min_messages flag being set to \"warning\".",
                "field_type": "impact"
            },
            {
                "field_data": "The log_min_messages flag controls which message levels are recorded in server logs. The higher the severity, the fewer messages are recorded. Hence it is recommended that all PostgreSQL instances are configured to have \" log_min_messages\" database flag set to warning.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1596"
        ]
    },
    {
        "unique_identifier": "99840033",
        "description": [
            {
                "field_data": "If the remediation of this control is not performed then it will not prevent from abuse and Denial-of-Service (DoS) attack on remote servers.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will result in the disabling of the log_statement_stats database flag in the unremediated SQL Server.",
                "field_type": "impact"
            },
            {
                "field_data": "When activated, this setting grants permission to run local stored procedures from remote servers or remote stored procedures from the local server. This functionality can be abused to launch a Denial-of-Service (DoS) attack on remote servers by offloading query processing to a target. To prevent abuse, we recommend disabling this setting.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1498"
        ]
    },
    {
        "unique_identifier": "99840034",
        "description": [
            {
                "field_data": "If the remediation of this control is not performed then it will not protect the DATABASES from the other users and could lead to data loss which could lead to a large business loss for the organization.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will result in the enabling of the skip_show_database flag in the unremediated SQL instance.",
                "field_type": "impact"
            },
            {
                "field_data": "When activated, this flag prevents users from using the SHOW DATABASES statement if they don't have the SHOW DATABASES privilege. With this setting, users without explicit permission aren't able to see databases that belong to other users. We recommend enabling this flag.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1580"
        ]
    },
    {
        "unique_identifier": "99840035",
        "description": [
            {
                "field_data": "If the remediation of this control is not performed then it will not protect the sensitive information, which could lead to a large business loss for the organization.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will result in the enabling of the 3625 database flag in the unremediated SQL Server instance.",
                "field_type": "impact"
            },
            {
                "field_data": "The trace flag limits the amount of information returned to users who are not members of the sysadmin fixed server role, by masking the parameters of some error messages using asterisks (******). To help prevent the disclosure of sensitive information, we recommend enabling this flag.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1580"
        ]
    },
    {
        "unique_identifier": "99840036",
        "description": [
            {
                "field_data": "If the remediation of this control is not performed then it increases the possibility of a compromised user gaining access to the instance which could leak data or sensitive information and could lead to a large business loss for the organization.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will result in the disabling of the user connections database flag in the unremediated SQL Server.",
                "field_type": "impact"
            },
            {
                "field_data": "The user connections option specifies the maximum number of simultaneous user connections that are allowed on an instance of SQL Server. Because it's a dynamic (self-configuring) option, SQL Server adjusts the maximum number of user connections automatically as needed, up to the maximum value allowable. The default value is 0, which means that up to 32,767 user connections are allowed. For this reason, we don't recommend configuring the user connections database flag.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1078"
        ]
    },
    {
        "unique_identifier": "99840037",
        "description": [
            {
                "field_data": "If the remediation of this control is not performed then it will not override global default values of the SET options for all users and which might cause unexpected results and can cause business loss for the organization.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will result in the disabling of the user options database flag in the unremediated SQL Server.",
                "field_type": "impact"
            },
            {
                "field_data": "The setting overrides global default values of the SET options for all users. Since users and applications might assume the default database SET options are in use, setting the user options might cause unexpected results. For this reason, we don't recommend configuring the user options database flag.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1078"
        ]
    },
    {
        "unique_identifier": "99840038",
        "description": [
            {
                "field_data": "Location restriction Organization policies are not enforced retroactively on already existing resources. This means that already existing resources that violate these policies will not be deleted/altered since there might be operational pitfalls as a result of taking such an action.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control can have major operational repercussion, and should be carried out only if crucial services are not being impacted critically.",
                "field_type": "impact"
            },
            {
                "field_data": "Organization policies can be set up to create restrictions on resources being assigned to certain regions. It limit the physical location of a new resource with the Organization Policy Service resource locations constraint. It can use the location property of a resource to identify where it is deployed and maintained by the service. For data-containing resources of some Google Cloud services, this property also reflects the location where data is stored. This constraint allows us to define the allowed Google Cloud locations where the resources for supported services in the hierarchy can be created. These policies should not be violated by individual resources if the restrictions are enforced with important business constraints in mind. Hence it is recommended that all instances are configured to comply with location restriction Organization policies.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1535"
        ]
    },
    {
        "unique_identifier": "99840038",
        "description": [
            {
                "field_data": "Location restriction Organization policies are not enforced retroactively on already existing resources. This means that already existing resources that violate these policies will not be deleted/altered since there might be operational pitfalls as a result of taking such an action.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control can have major operational repercussion, and should be carried out only if crucial services are not being impacted critically.",
                "field_type": "impact"
            },
            {
                "field_data": "Organization policies can be set up to create restrictions on resources being assigned to certain regions. It limit the physical location of a new resource with the Organization Policy Service resource locations constraint. It can use the location property of a resource to identify where it is deployed and maintained by the service. For data-containing resources of some Google Cloud services, this property also reflects the location where data is stored. This constraint allows us to define the allowed Google Cloud locations where the resources for supported services in the hierarchy can be created. These policies should not be violated by individual resources if the restrictions are enforced with important business constraints in mind. Hence it is recommended that all instances are configured to comply with location restriction Organization policies.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1535"
        ]
    },
    {
        "unique_identifier": "99840039",
        "description": [
            {
                "field_data": "A publicly accessible bucket can potentially expose sensitive data to attackers by making it easier for them to gain unauthorized access to it. This can lead to a major business loss for the organization.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the Cloud Storage bucket being accessible to only those users that have explicitly given permission to access them through an IAM role.",
                "field_type": "impact"
            },
            {
                "field_data": "Cloud Storage buckets are datastores being used to store objects on the Google Cloud. These may contain sensitive data belonging to the organization. A bucket being publicly accessible to anyone on the internet (roles assigned with allUsers and allAuthenticatedUsers members) can lead to unauthorized access and subsequent loss of data. Hence, it is recommended that no Cloud Storage buckets are publicly accessible.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1583"
        ]
    },
    {
        "unique_identifier": "99840040",
        "description": [
            {
                "field_data": "A publicly accessible log bucket can potentially expose logging data to attackers by making it easier for them to gain unauthorized access to it. This can lead to a major business loss for the organization.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the Cloud Storage log bucket being accessible to only those users that have explicitly been given permission to access it through a particular IAM role.",
                "field_type": "impact"
            },
            {
                "field_data": "Cloud Storage log buckets are buckets that are being used as log sinks, therefore they could be storing sensitive data in the form of logs belonging to critical resources. Having these log buckets accessible to anyone on the internet (roles assigned with allUsers and allAuthenticatedUsers members) can lead to a loss of sensitive data. Hence, it is recommended that no Cloud Storage log buckets are publicly accessible.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1583"
        ]
    },
    {
        "unique_identifier": "99840047",
        "description": [
            {
                "field_data": "Not making use of a CMEK prevents the client from having increased control over the behaviour of the encryption process, for example - the rotation policy of the encryption keys.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control results in the encryption of assets with customer managed keys as opposed to Google's default encryption-at-rest facility. This may result in an additional cost to the customer.",
                "field_type": "impact"
            },
            {
                "field_data": "CMEKs are customer managed keys that provide an extra layer of encryption over Google's standard data at rest encryption. The standard encryption is wrapped by the customer managed key, thus giving the customer more control over the encryption of the organization's data, since the customer gets to control the CMEK's rotation policy. Hence it is recommended that all Cloud Storage buckets are encrypted with CMEKs.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1596"
        ]
    },
    {
        "unique_identifier": "99840048",
        "description": [
            {
                "field_data": "Not having Uniform Level Access enabled requires each object in the bucket to be assigned their own separate access policy. This leads to a greater overhead and also leaves more room for human error exposing the data being stored in the bucket.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the application of a uniform access control policy being applied to all the objects stored in the remediated bucket.",
                "field_type": "impact"
            },
            {
                "field_data": "Uniform Level Access simplifies access control for Cloud Storage buckets by disabling object level access. The access at bucket level becomes the only method to access the objects in a bucket by using bucket level IAM permissions. This simplifies the access management for buckets. Hence it is recommended that all Cloud Storage buckets are configured to have Uniform Level Access enabled.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1596"
        ]
    },
    {
        "unique_identifier": "99840049",
        "description": [
            {
                "field_data": "By default, VMs that do not have a public IP address assigned to them can only send packets to destinations within the private network of GCP resources, hence they can not communicate with public Google APIs.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will allow VMs that do not have a public IP address to communicate with public Google APIs in order make use of them in their application's functioning.",
                "field_type": "impact"
            },
            {
                "field_data": "Private Google Access enables VMs that have only private IP addresses to interact with the public Google APIs. Hence, it is recommended that all private subnetworks have Private Google Access Enabled.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1590"
        ]
    },
    {
        "unique_identifier": "99840050",
        "description": [
            {
                "field_data": "If logging for storage buckets is disabled it makes more difficult to keep track of storage bucket activities and in case any suspicious activity goes unnoticed due to the lack of logging for storage buckets it can cause monetary losses to the organization.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "If the remediation of this control is performed then, the charges for all logs being stored in buckets could result in an increased storage cost for the organization.",
                "field_type": "impact"
            },
            {
                "field_data": "Logging for storage buckets includes access logs and storage logs. Access logs monitor and store all the requests that are made to the bucket, while storage logs provide storage consumption information for the bucket. This information can help monitor the costs of log storage as well as help to maintaining integrity of the data being stored in the buckets. Hence, it is recommended that logging is enabled for all storage buckets.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1584"
        ]
    },
    {
        "unique_identifier": "99840051",
        "description": [
            {
                "field_data": "A bucket without a locked retention policy is more prone to the possibility of accidental or malicious deletion. Critical data can be lost if the bucket is deleted prematurely.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "Locking a retention policy is an irreversible act and can only be undone by deleting the entire bucket.",
                "field_type": "impact"
            },
            {
                "field_data": "A retention policy protects the contents of a bucket and the bucket itself from being deleted before a stipulated time period. A lock being applied on the retention policy prevents the stipulated time period specified on the policy from being reduced. Once a lock is applied, a retention policy's stated time period can only be increased, never decreased. The bucket on which a locked retention policy is applied can be deleted only after every object stored in it has met the stipulated time period.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1596"
        ]
    },
    {
        "unique_identifier": "99840052",
        "description": [
            {
                "field_data": "Not enabling object versioning makes buckets and the log sinks configured for them more vulnerable to loss of data due to accidental deletion or overwrites.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "If the remediation of this control is performed, then it could result in the increase storage of costs for the organization.",
                "field_type": "impact"
            },
            {
                "field_data": "Object Versioning is a feature of cloud storage that enables the retrieval of deleted or overwritten objects. Object versioning increases the storage costs but it provides security for objects when they are deleted or overwritten. On enabling the object versioning in the GCP bucket, a noncurrent version of the object is created every time when the object is overwritten or deleted. It is recommended to enable Object Versioning on all storage buckets since it protects against the accidental deletion of data.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1584"
        ]
    },
    {
        "unique_identifier": "99840038",
        "description": [
            {
                "field_data": "Location restriction Organization policies are not enforced retroactively on already existing resources. This means that already existing resources that violate these policies will not be deleted/altered since there might be operational pitfalls as a result of taking such an action.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control can have major operational repercussion, and should be carried out only if crucial services are not being impacted critically.",
                "field_type": "impact"
            },
            {
                "field_data": "Organization policies can be set up to create restrictions on resources being assigned to certain regions. It limit the physical location of a new resource with the Organization Policy Service resource locations constraint. It can use the location property of a resource to identify where it is deployed and maintained by the service. For data-containing resources of some Google Cloud services, this property also reflects the location where data is stored. This constraint allows us to define the allowed Google Cloud locations where the resources for supported services in the hierarchy can be created. These policies should not be violated by individual resources if the restrictions are enforced with important business constraints in mind. Hence it is recommended that all instances are configured to comply with location restriction Organization policies.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1535"
        ]
    },
    {
        "unique_identifier": "99840053",
        "description": [
            {
                "field_data": "A public IP address leaves the Compute Engine instance vulnerable to unauthorized access from attackers. This could potentially lead to the loss of data associated with the instance, thus leading to a major business loss for the organization.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the public network interface of the VM being deleted. It should then be replaced by an internal network interface in order to ensure the smooth continuation of operations.",
                "field_type": "impact"
            },
            {
                "field_data": "No public IP addresses should be used in a Compute Engine instance. This reduces the potential attack surface for the instance, making it less vulnerable. Hence it is recommended that no Compute Engine instances are configured to use a public IP address.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1595"
        ]
    },
    {
        "unique_identifier": "99840054",
        "description": [
            {
                "field_data": "Using project-wide ssh keys increases the attack surface that can be targeted by attackers. This means that the attackers will be able to access a much larger amount of sensitive data if a project-wide ssh key is compromised (as opposed to multiple keys being used for different resources in a project), thus leading to a much greater business loss for the organization.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the deletion of any project-wide ssh keys being used for authentication purposes. Any VM instance making use of these keys will need to be configured with other methods of authentication in order to ensure continued smooth operation",
                "field_type": "impact"
            },
            {
                "field_data": "Project-wide ssh keys should be not used in order to grant access to a Compute Engine instance. Instead, instance-specific ssh keys should be used to grant access. A project-wide key being compromised would put all the instances using the key at risk, resulting in the increase of the attack surface. Hence, it is recommended that project wide ssh keys are not used for Compute Engine VMs.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1584"
        ]
    },
    {
        "unique_identifier": "99840055",
        "description": [
            {
                "field_data": "Not enabling Secure Boot for Compute Engine VMs leaves them more vulnerable to attackers trying to compromise them using rootkits/bootkits. At worst, it could compromise the kernel of the operating system itself and provide the attackers with admin level access on the instance. If an attack of this nature is successful, the organization may face the loss of all data related to the VM instance in question.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the activation of Secure Boot on the remediated VM instance. It is important to note that if the firmware being used in the boot configuration of a VM doesn't comply with the safety compliances of Secure Boot- it will not be allowed to boot once Secure Boot is enabled. In this case, Secure Boot will have to be disabled once so that the VM can be booted to resolve the issue- and then enabled once again.",
                "field_type": "impact"
            },
            {
                "field_data": "Secure Boot for VMs serves to protect the Compute Engine instances from threats such as rootkits and bootkits. A rootkit or bootkit is a collection of software that allows the attackers to gain access to resources on an instance which would not be possible under normal conditions. For instance- a root level program on the instance's operating system which would require administrator privilege under normal conditions. Hence, it is recommended that all Compute Engine instances have Secure Boot enabled.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1584"
        ]
    },
    {
        "unique_identifier": "99840056",
        "description": [
            {
                "field_data": "The serial port console uses a connection methodology that does not support the restriction of user access based on IP addresses. This means that attackers can connect to the serial console from an external IP address and gain control of the VM, which can cause a significant data loss to the organization.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will result in remote connections to the serial console of the Compute Engine instance being disallowed.",
                "field_type": "impact"
            },
            {
                "field_data": "Serial ports allow remote connections to the instance's serial console. The serial port console does not support the restriction of access on the basis of IP address. Hence the use of serial ports should be disabled as external connections should not be allowed to the VM's serial console from an untrusted IP address in order to prevent unauthorized access of the VM.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1590"
        ]
    },
    {
        "unique_identifier": "99840057",
        "description": [
            {
                "field_data": "In case a Compute Engine VM is compromised and has permissions to use the default Compute Engine service account, the attackers will immediately attain the Editor role by virtue of the privilege escalation that would occur in this scenario. This could lead to a major business loss as the attackers would have access to all the data related to the project to which the service account belongs to.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the removal of the default Compute Engine service account from the list of service accounts the VM has permissions to use. A new service account should be employed in place of the default service account in order to ensure continued smooth operation for the service/application it was being used for.",
                "field_type": "impact"
            },
            {
                "field_data": "The default Compute Engine service account exists in all projects that have Compute Engine API enabled. The service account has the Editor role assigned to it. Hence an instance should not be configured to use the Project's default Compute Enginer service account to avoid privilege escalation and unauthorized access.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1078"
        ]
    },
    {
        "unique_identifier": "99840058",
        "description": [
            {
                "field_data": "In case a Compute Engine VM is compromised and has permissions to use the default Compute Engine service account, the attackers will immediately attain the Editor role by virtue of the privilege escalation that would occur in this scenario. This could lead to a major business loss as the attackers would have access to all the data related to the project to which the service account belongs to.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the remediated instance not having universal access to Cloud APIs via the default compute engine service account. The service account or VM instance may need to be given particular permissions to continued smooth operation of the applications using them.",
                "field_type": "impact"
            },
            {
                "field_data": "The default Compute Engine service account exists in all projects that have Compute Engine API enabled. This service account has the Editor role assigned to it. If the instance is configured with the service account scope to allow full access to all cloud APIs, it may enable the Compute Instance VM to carry out API calls the that it does not have IAM permissions for. This may increase the potential damage that can be caused by an attack that compromises a VM with this configuration.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1106"
        ]
    },
    {
        "unique_identifier": "99840059",
        "description": [
            {
                "field_data": "Having IP forwarding enabled for instances that have a public subnet associated with them can lead to potential attacks which could compromise the entire network of instances. This could lead to loss of data in multiple instances, thus causing a major business loss for the organization.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the unremediated instance being deleted and being replaced by an identical instance that does not have IP forwarding enabled. Adequate measures should be taken to integrate the new instance wherever required to prevent the breaking of applications or services.",
                "field_type": "impact"
            },
            {
                "field_data": "IP forwarding being enabled on Compute Engine VMs can lead to unwanted disclosure of information and subsequent loss of data. Hence it is recommended that all Compute Engine instances are configured to have IP forwarding disabled.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1595"
        ]
    },
    {
        "unique_identifier": "99840060",
        "description": [
            {
                "field_data": "Not enabling Shielded VM for Compute Engine VMs leaves them more vulnerable to attackers trying to compromise them using toolkits/bootkits. If an attack of this nature is successful- the organization may face the loss of all data related to the VM in question.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the activation of Shielded VM on the remediated VM instance. One of the measures implemented under Shielded VM is Secure Boot. It is important to note that if the firmware being used in the boot configuration of a VM doesn't comply with the safety compliances of Secure Boot- it will not be allowed to boot once the Secure Boot is enabled. In this case, Secure Boot will have to be disabled once so that the VM can be booted to resolve the issue- and then enabled once again.",
                "field_type": "impact"
            },
            {
                "field_data": "Shielded VM is a configuration for Compute Engine instances that uses a set of hardened controls to protect a VM by ensuring that its boot loader and firmware are signed and verified. It protects VMs from rootkits and bootkits.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1203"
        ]
    },
    {
        "unique_identifier": "99840061",
        "description": [
            {
                "field_data": "Not enabling Confidential VM deprives the VM instances of inline memory encryption, which provides runtime protection against potential attacks.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will not only lead to higher performance output with the use of the AMD Rome family processors- but also provide runtime encryption to protect against potential attacks.",
                "field_type": "impact"
            },
            {
                "field_data": "Confidential VM is a organization policy that enforces the use of runtime memory encryption on Compute Engine instances when enabled. This helps protect VMs against runtime memory attacks. Hence it is recommended that all Compute Engine instances are configured to have Confidential VM enabled.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1203"
        ]
    },
    {
        "unique_identifier": "99840154",
        "description": [
            {
                "field_data": "Not enabling Confidential VM deprives the VM instances of inline memory encryption, which provides runtime protection against potential attacks.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control can have major operational repercussion, as Confidential VM incurs additional costs on top of Compute Engine pricing.",
                "field_type": "impact"
            },
            {
                "field_data": "Organization requires this VM to have the Confidential VM service enabled. VMs that don't have this service enabled will not use runtime memory encryption, exposing them to runtime memory attacks. Hence it is recommended that all Compute Engine instances are configured to have Confidential VM enabled.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1203"
        ]
    },
    {
        "unique_identifier": "99840045",
        "description": [
            {
                "field_data": "An open port that can be accessed from any IP address can potentially be misused by malicious elements to disrupt the services pertaining to that port. Having an open SSH port configured by a firewall can lead to a serious loss of data and disruption of proccesses from the port.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the removal of firewall rules pertaining to open SSH ports. They will be replaced by specific addresses belonging to the services leveraging the firewall rules to get access to the ports.",
                "field_type": "impact"
            },
            {
                "field_data": "A firewall rule pertaining to an open SSH port allows any connections from any IP address to the port (SSH service ports are TCP-22 and SCTP-22). This can leave the SSH services vulnerable to external attacks. Hence, it is recommended that no firewall rule that allows an open port should exist.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1568"
        ]
    },
    {
        "unique_identifier": "99840046",
        "description": [
            {
                "field_data": "A firewall rule that allows connections from all IP adresses or from all ports can unnecessarily expose resources to attacks from unintended sources. Such a firewall rule can lead to unauthorized access and potentially expose the organization's sensitive data and critical resources.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the removal of firewall rules that allow connections from all ports or any IP addresses. Instead, the new rules will have specific allowed IP addresses which will be given permission to connect to specific ports as needed by the services.",
                "field_type": "impact"
            },
            {
                "field_data": "A firewall rule that is open to all IP addresses or from all ports can unnecessarily expose the owner's resources to attacks. Instead, the rules should be focussed on specific IP address belonging to trusted networks.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1568"
        ]
    },
    {
        "unique_identifier": "99840062",
        "description": [
            {
                "field_data": "An open port that can be accessed from any IP address can potentially be misused by malicious elements to disrupt the services pertaining to that port. Having an open CiscoSecure/WebSM port configured by a firewall can lead to a serious loss of data and disruption of processes from the port.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the removal of firewall rules pertaining to open CiscoSecure/WebSM ports. They will be replaced by specific addresses belonging to the services leveraging the firewall rules to get access to the ports.",
                "field_type": "impact"
            },
            {
                "field_data": "A firewall rule pertaining to an open CiscoSecure/WebSM port allows any connections from any IP address to the port (CiscoSecure/WebSM service port is TCP - 9090). This can leave the CiscoSecure/WebSM services vulnerable to external attacks. Hence, it is recommended that no firewall rule that allows an open port should exist.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1568"
        ]
    },
    {
        "unique_identifier": "99840063",
        "description": [
            {
                "field_data": "An open port that can be accessed from any IP address can potentially be misused by malicious elements to disrupt the services pertaining to that port. Having an open Directory port configured by a firewall can lead to a serious loss of data and disruption of processes from the port.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the removal of firewall rules pertaining to open Directory service ports. They will be replaced by specific addresses belonging to the services leveraging the firewall rules to get access to the ports.",
                "field_type": "impact"
            },
            {
                "field_data": "A firewall rule pertaining to an open Directory port allows any connections from any IP address to the port (Directory service ports are TCP- 445 and UDP- 445). This can leave the Directory services vulnerable to external attacks. Hence, it is recommended that no firewall rule that allows an open port should exist.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1568"
        ]
    },
    {
        "unique_identifier": "99840066",
        "description": [
            {
                "field_data": "An open port that can be accessed from any IP address can potentially be misused by malicious elements to disrupt the services pertaining to that port. Having an open RDP port configured by a firewall can lead to a serious loss of data and disruption of proccesses from the port.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the removal of firewall rules pertaining to open RDP ports. They will be replaced by specific addresses belonging to the services leveraging the firewall rules to get access to the ports.",
                "field_type": "impact"
            },
            {
                "field_data": "A firewall rule pertaining to an open RDP port allows any connections from any IP address to the port (RDP service ports are TCP - 3389 and UDP- 3389). This can leave the RDP services vulnerable to external attacks. Hence, it is recommended that no firewall rule that allows an open port should exist.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1568"
        ]
    },
    {
        "unique_identifier": "99840067",
        "description": [
            {
                "field_data": "An open port that can be accessed from any IP address can potentially be misused by malicious elements to disrupt the services pertaining to that port. Having an open TELNET port configured by a firewall can lead to a serious loss of data and disruption of proccesses from the port.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the removal of firewall rules pertaining to open TELNET ports. They will be replaced by specific addresses belonging to the services leveraging the firewall rules to get access to the ports.",
                "field_type": "impact"
            },
            {
                "field_data": "A firewall rule pertaining to an open TELNET port allows any connections from any IP address to the port (TELNET service port is TCP-23). This can leave the TELNET services vulnerable to external attacks. Hence, it is recommended that no firewall rule that allows an open port should exist.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1568"
        ]
    },
    {
        "unique_identifier": "99840068",
        "description": [
            {
                "field_data": "Allowing unrestricted outbound connections from a Compute Engine instance can potentially lead to a major loss of data- in case that instance is compromised, it leads to an increased possibility of malicious activity like a DDOS attack.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control results in the creation of a new firewall rule that denies egress network traffic.",
                "field_type": "impact"
            },
            {
                "field_data": "Configuring a firewall rule to deny egress network traffic prevents any unwanted outbound network connections, unless explicitly authorized by other firewalls.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1020"
        ]
    },
    {
        "unique_identifier": "99840069",
        "description": [
            {
                "field_data": "Not enabling firewall rule logging makes it harder to take immediate action against any unauthorized access to Compute Engine resources. This increases the potential harm that can be caused by such a security breach, thus also increasing the business loss that the organization may incur in the process.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control results in the enabling of logging for unremediated firewall rules. It should be noted that enabling logging can result in a substantial cost increase for the client depending on the volume of information being stored.",
                "field_type": "impact"
            },
            {
                "field_data": "Firewall rule logging allows the resource owner to audit and analyze the effectiveness of a firewall's rules by maintaining logs. It may provide early warnings of unauthorized access to the network. Hence, it is recommended that firewall rule logging is enabled for Compute Engine Firewalls.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1568"
        ]
    },
    {
        "unique_identifier": "99840070",
        "description": [
            {
                "field_data": "An open port that can be accessed from any IP address can potentially be misused by malicious elements to disrupt the services pertaining to that port. Having an open Cassandra port configured by a firewall can lead to a serious loss of data and disruption of processes from the port.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the removal of firewall rules pertaining to open Cassandra ports. They will be replaced by specific addresses belonging to the services leveraging the firewall rules to get access to the ports.",
                "field_type": "impact"
            },
            {
                "field_data": "A firewall rule pertaining to an open Cassandra port allows any connections from any IP address to the port (Cassandra service ports are TCP - 7000, 7001, 7199, 8888, 9042, 9160, 61620, 61621). This can leave the Cassandra services vulnerable to external attacks. Hence it is recommended that no firewall rule that allows an open port should exist.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1568"
        ]
    },
    {
        "unique_identifier": "99840071",
        "description": [
            {
                "field_data": "An open port that can be accessed from any IP address can potentially be misused by malicious elements to disrupt the services pertaining to that port. Having an open DNS port configured by a firewall can lead to a serious loss of data and disruption of processes from the port.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the removal of firewall rules pertaining to open DNS ports. They will be replaced by specific addresses belonging to the services leveraging the firewall rules to get access to the ports.",
                "field_type": "impact"
            },
            {
                "field_data": "A firewall rule pertaining to an open DNS port allows any connections from any IP address to the port (DNS service ports are TCP- 53 and UDP- 53). This can leave the DNS services vulnerable to external attacks. Hence it is recommended that no firewall rule that allows an open port should exist.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1568"
        ]
    },
    {
        "unique_identifier": "99840072",
        "description": [
            {
                "field_data": "An open port that can be accessed from any IP address can potentially be misused by malicious elements to disrupt the services pertaining to that port. Having an open Elasticsearch port configured by a firewall can lead to a serious loss of data and disruption of processes from the port.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the removal of firewall rules pertaining to open Elasticsearch ports. They will be replaced by specific addresses belonging to the services leveraging the firewall rules to get access to the ports.",
                "field_type": "impact"
            },
            {
                "field_data": "A firewall rule pertaining to an open Elasticsearch port allows any connections from any IP address to the port (Elasticsearch service ports are TCP- 9200, 9300). This can leave the Elasticsearch services vulnerable to external attacks. Hence it is recommended that no firewall rule that allows an open port should exist.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1568"
        ]
    },
    {
        "unique_identifier": "99840073",
        "description": [
            {
                "field_data": "An open port that can be accessed from any IP address can potentially be misused by malicious elements to disrupt the services pertaining to that port. Having an open FTP port configured by a firewall can lead to a serious loss of data and disruption of processes from the port.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the removal of firewall rules pertaining to open FTP ports. They will be replaced by specific addresses belonging to the services leveraging the firewall rules to get access to the ports.",
                "field_type": "impact"
            },
            {
                "field_data": "A firewall rule pertaining to an open FTP port allows any connections from any IP address to the port (FTP services port is TCP- 21). This can leave the FTP services vulnerable to external attacks. Hence it is recommended that no firewall rule that allows an open port should exist.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1568"
        ]
    },
    {
        "unique_identifier": "99840074",
        "description": [
            {
                "field_data": "An open port that can be accessed from any IP address can potentially be misused by malicious elements to disrupt the services pertaining to that port. Having an open HTTP port configured by a firewall can lead to a serious loss of data and disruption of processes from the port.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the removal of firewall rules pertaining to open HTTP ports. They will be replaced by specific addresses belonging to the services leveraging the firewall rules to get access to the ports.",
                "field_type": "impact"
            },
            {
                "field_data": "A firewall rule pertaining to an open HTTP port allows any connections from any IP address to the port (HTTP services port is TCP- 80). This can leave the HTTP services vulnerable to external attacks. Hence it is recommended that no firewall rule that allows an open port should exist.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1568"
        ]
    },
    {
        "unique_identifier": "99840075",
        "description": [
            {
                "field_data": "An open port that can be accessed from any IP address can potentially be misused by malicious elements to disrupt the services pertaining to that port. Having an open LDAP port configured by a firewall can lead to a serious loss of data and disruption of processes from the port.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the removal of firewall rules pertaining to open LDAP ports. They will be replaced by specific addresses belonging to the services leveraging the firewall rules to get access to the ports.",
                "field_type": "impact"
            },
            {
                "field_data": "A firewall rule pertaining to an open LDAP port allows any connections from any IP address to the port (LDAP services ports are TCP- 389, 636 and UDP- 389). This can leave the LDAP services vulnerable to external attacks. Hence it is recommended that no firewall rule that allows an open port should exist.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1568"
        ]
    },
    {
        "unique_identifier": "99840076",
        "description": [
            {
                "field_data": "An open port that can be accessed from any IP address can potentially be misused by malicious elements to disrupt the services pertaining to that port. Having an open Memcached port configured by a firewall can lead to a serious loss of data and disruption of processes from the port.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the removal of firewall rules pertaining to open Memcached ports. They will be replaced by specific addresses belonging to the services leveraging the firewall rules to get access to the ports.",
                "field_type": "impact"
            },
            {
                "field_data": "A firewall rule pertaining to an open Memcached port allows any connections from any IP address to the port (Memcached service ports are TCP- 11211, 11214, 11215 and UDP- 11211, 11214, 11215). This can leave the Memcached services vulnerable to external attacks. Hence it is recommended that no firewall rule that allows an open port should exist.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1568"
        ]
    },
    {
        "unique_identifier": "99840077",
        "description": [
            {
                "field_data": "An open port that can be accessed from any IP address can potentially be misused by malicious elements to disrupt the services pertaining to that port. Having an open MongoDB port configured by a firewall can lead to a serious loss of data and disruption of processes from the port.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the removal of firewall rules pertaining to open MongoDB ports. They will be replaced by specific addresses belonging to the services leveraging the firewall rules to get access to the ports.",
                "field_type": "impact"
            },
            {
                "field_data": "A firewall rule pertaining to an open MongoDB port allows any connections from any IP address to the port (MongoDB service ports are TCP - 27017, 27018, 27019). This can leave the MongoDB services vulnerable to external attacks. Hence it is recommended that no firewall rule that allows an open port should exist.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1568"
        ]
    },
    {
        "unique_identifier": "99840078",
        "description": [
            {
                "field_data": "An open port that can be accessed from any IP address can potentially be misused by malicious elements to disrupt the services pertaining to that port. Having an open MySQL port configured by a firewall can lead to a serious loss of data and disruption of processes from the port.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the removal of firewall rules pertaining to open MySQL ports. They will be replaced by specific addresses belonging to the services leveraging the firewall rules to get access to the ports.",
                "field_type": "impact"
            },
            {
                "field_data": "A firewall rule pertaining to an open MySQL port allows any connections from any IP address to the port (MySQL service port is TCP - 3306). This can leave the MySQL services vulnerable to external attacks.Hence it is recommended that no firewall rule that allows an open port should exist.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1568"
        ]
    },
    {
        "unique_identifier": "99840079",
        "description": [
            {
                "field_data": "An open port that can be accessed from any IP address can potentially be misused by malicious elements to disrupt the services pertaining to that port. Having an open NetBIOS port configured by a firewall can lead to a serious loss of data and disruption of processes from the port.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the removal of firewall rules pertaining to open NetBIOS ports. They will be replaced by specific addresses belonging to the services leveraging the firewall rules to get access to the ports.",
                "field_type": "impact"
            },
            {
                "field_data": "A firewall rule pertaining to an open NetBIOS port allows any connections from any IP address to the port(NetBIOS service ports are TCP - 137, 138, 139 and UDP - 137, 138, 139). This can leave the NetBIOS services vulnerable to external attacks. Hence it is recommended that no firewall rule that allows an open port should exist.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1568"
        ]
    },
    {
        "unique_identifier": "99840080",
        "description": [
            {
                "field_data": "An open port that can be accessed from any IP address can potentially be misused by malicious elements to disrupt the services pertaining to that port. Having an open OracleDB port configured by a firewall can lead to a serious loss of data and disruption of processes from the port.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the removal of firewall rules pertaining to open OracleDB ports. They will be replaced by specific addresses belonging to the services leveraging the firewall rules to get access to the ports.",
                "field_type": "impact"
            },
            {
                "field_data": "A firewall rule pertaining to an open OracleDB port allows any connections from any IP address to the port (OracleDB service ports are TCP - 1521, 2483, 2484 and UDP - 2483, 2484). This can leave the OracleDB services vulnerable to external attacks. Hence it is recommended that no firewall rule that allows an open port should exist.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1568"
        ]
    },
    {
        "unique_identifier": "99840082",
        "description": [
            {
                "field_data": "An open port that can be accessed from any IP address can potentially be misused by malicious elements to disrupt the services pertaining to that port. Having an open POP3 port configured by a firewall can lead to a serious loss of data and disruption of processes from the port.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the removal of firewall rules pertaining to open POP3 ports. They will be replaced by specific addresses belonging to the services leveraging the firewall rules to get access to the ports.",
                "field_type": "impact"
            },
            {
                "field_data": "A firewall rule pertaining to an open POP3 port allows any connections from any IP address to the port (POP3 service port is TCP - 110). This can leave the POP3 services vulnerable to external attacks. Hence it is recommended that no firewall rule that allows an open port should exist.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1568"
        ]
    },
    {
        "unique_identifier": "99840083",
        "description": [
            {
                "field_data": "An open port that can be accessed from any IP address can potentially be misused by malicious elements to disrupt the services pertaining to that port. Having an open PostgreSQL port configured by a firewall can lead to a serious loss of data and disruption of processes from the port.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the removal of firewall rules pertaining to open PostgreSQL ports. They will be replaced by specific addresses belonging to the services leveraging the firewall rules to get access to the ports.",
                "field_type": "impact"
            },
            {
                "field_data": "A firewall rule pertaining to an open PostgreSQL port allows any connections from any IP address to the port (PostgreSQL services ports are TCP - 5432 and UDP - 5432). This can leave the PostgreSQL services vulnerable to external attacks. Hence it is recommended that no firewall rule that allows an open port should exist.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1568"
        ]
    },
    {
        "unique_identifier": "99840084",
        "description": [
            {
                "field_data": "An open port that can be accessed from any IP address can potentially be misused by malicious elements to disrupt the services pertaining to that port. Having an open REDIS port configured by a firewall can lead to a serious loss of data and disruption of processes from the port.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the removal of firewall rules pertaining to open REDIS ports. They will be replaced by specific addresses belonging to the services leveraging the firewall rules to get access to the ports.",
                "field_type": "impact"
            },
            {
                "field_data": "A firewall rule pertaining to an open REDIS port allows any connections from any IP address to the port (REDIS service port is TCP - 6379). This can leave the REDIS services vulnerable to external attacks. Hence it is recommended that no firewall rule that allows an open port should exist.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1568"
        ]
    },
    {
        "unique_identifier": "99840085",
        "description": [
            {
                "field_data": "An open port that can be accessed from any IP address can potentially be misused by malicious elements to disrupt the services pertaining to that port. Having an open SMTP port configured by a firewall can lead to a serious loss of data and disruption of processes from the port.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the removal of firewall rules pertaining to open SMTP ports. They will be replaced by specific addresses belonging to the services leveraging the firewall rules to get access to the ports.",
                "field_type": "impact"
            },
            {
                "field_data": "A firewall rule pertaining to an open SMTP port allows any connections from any IP address to the port (SMTP service port is TCP-25). This can leave the SMTP services vulnerable to external attacks. Hence it is recommended that no firewall rule that allows an open port should exist.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1568"
        ]
    },
    {
        "unique_identifier": "99840038",
        "description": [
            {
                "field_data": "Location restriction Organization policies are not enforced retroactively on already existing resources. This means that already existing resources that violate these policies will not be deleted/altered since there might be operational pitfalls as a result of taking such an action.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control can have major operational repercussion, and should be carried out only if crucial services are not being impacted critically.",
                "field_type": "impact"
            },
            {
                "field_data": "Organization policies can be set up to create restrictions on resources being assigned to certain regions. It limit the physical location of a new resource with the Organization Policy Service resource locations constraint. It can use the location property of a resource to identify where it is deployed and maintained by the service. For data-containing resources of some Google Cloud services, this property also reflects the location where data is stored. This constraint allows us to define the allowed Google Cloud locations where the resources for supported services in the hierarchy can be created. These policies should not be violated by individual resources if the restrictions are enforced with important business constraints in mind. Hence it is recommended that all instances are configured to comply with location restriction Organization policies.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1535"
        ]
    },
    {
        "unique_identifier": "99840064",
        "description": [
            {
                "field_data": "ABAC does not provide the same level of fine-grained access control as RBAC. This means that in case a user or resource is compromised, it is more likely to escalate into a larger security problem. Moreover, the organization will also miss out on the regular patches and updates that will be coming to RBAC for GKE clusters.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will result in any existing access control under the Legacy ABAC to be discontinued. Instead, the resource owners will need to configure RBAC for their clusters to ensure continued smooth operations.",
                "field_type": "impact"
            },
            {
                "field_data": "Legacy Authorization or Attribute-Based Access Control (ABAC) for GKE clusters has been replaced by the newer and more secure Rule-Based Access Control (RBAC) from GKE version 1.8 onwards. RBAC provides better security by ensuring that users only get permissions granted to them at the cluster and namespace level. Hence it is recommended that all GKE clusters are configured to have legacy authorization (ABAC) disabled.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1078"
        ]
    },
    {
        "unique_identifier": "99840065",
        "description": [
            {
                "field_data": "The highly privileged service account backing the GKE web UI being compromised by attackers can result in unauthorized access, leading to loss of data. This could result in a significant business loss for the organization.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the GKE web UI being disabled for the cluster it is carried out for.",
                "field_type": "impact"
            },
            {
                "field_data": "The GKE web UI dashboard has a highly privileged Kubernetes service account backing it. The Cloud Console can perform most of the functions that GKE web UI performs, thus enabling it unnecessarily increases the attack surface for the cluster. Hence it is recommended that all GKE clusters are configured to have GKE web UI disabled.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1609"
        ]
    },
    {
        "unique_identifier": "99840065",
        "description": [
            {
                "field_data": "The highly privileged service account backing the GKE web UI being compromised by attackers can result in unauthorized access, leading to loss of data. This could result in a significant business loss for the organization.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the GKE web UI being disabled for the cluster it is carried out for.",
                "field_type": "impact"
            },
            {
                "field_data": "The GKE web UI dashboard has a highly privileged Kubernetes service account backing it. The Cloud Console can perform most of the functions that GKE web UI performs, thus enabling it unnecessarily increases the attack surface for the cluster. Hence it is recommended that all GKE clusters are configured to have GKE web UI disabled.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1609"
        ]
    },
    {
        "unique_identifier": "99840087",
        "description": [
            {
                "field_data": "Not having auto upgrade enabled on a GKE cluster results in the cluster having to be upgraded to the latest version manually in order to keep up with the latest security patches and features that come along with every new version of Kubernetes.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control enables auto upgrade on the unremediated control, which results in the cluster being automatically upgraded to the latest version of Kubernetes whenever it is made available.",
                "field_type": "impact"
            },
            {
                "field_data": "GKE has an auto upgrade feature which is responsible for keeping clusters and node pools on the newest stable version of Kubernetes. Having the latest version of Kubernetes running.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1613"
        ]
    },
    {
        "unique_identifier": "99840088",
        "description": [
            {
                "field_data": "Not having logging enabled on a GKE cluster makes it more difficult to diagnose security or performance related issues. It takes longer for issues to be resolved and harder to monitor usage metrics if logging is disabled.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control enables Cloud Logging on the unremediated cluster. Cloud Logging can result in significant monetary costs for the client depending on the volume of logs being consumed.",
                "field_type": "impact"
            },
            {
                "field_data": "Having Cloud Logging enabled on GKE clusters is helpful in monitoring usage and investigating security issues. Hence it is recommended that all GKE clusters are configured to have logging enabled.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1613"
        ]
    },
    {
        "unique_identifier": "99840089",
        "description": [
            {
                "field_data": "Not having monitoring enabled on a GKE cluster makes it more difficult to diagnose security or performance related issues. It takes longer for issues to be resolved and harder to monitor usage metrics if monitoring is disabled.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control enables Cloud Monitoring on the unremediated cluster. Cloud Monitoring can result in significant monetary costs for the client depending on the volume of information being consumed.",
                "field_type": "impact"
            },
            {
                "field_data": "Having Cloud Monitoring enabled on GKE clusters is helpful in monitoring usage and investigating security issues. Hence it is recommended that all GKE clusters are configured to have monitoring enabled.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1613"
        ]
    },
    {
        "unique_identifier": "99840089",
        "description": [
            {
                "field_data": "Not having monitoring enabled on a GKE cluster makes it more difficult to diagnose security or performance related issues. It takes longer for issues to be resolved and harder to monitor usage metrics if monitoring is disabled.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control enables Cloud Monitoring on the unremediated cluster. Cloud Monitoring can result in significant monetary costs for the client depending on the volume of information being consumed.",
                "field_type": "impact"
            },
            {
                "field_data": "Having Cloud Monitoring enabled on GKE clusters is helpful in monitoring usage and investigating security issues. Hence it is recommended that all GKE clusters are configured to have monitoring enabled.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1613"
        ]
    },
    {
        "unique_identifier": "99840091",
        "description": [
            {
                "field_data": "Not using COS as your cluster's operating system goes against Google's recommendation for GKE. Google's recommendations for GKE should be considered as the industry standard for security and performance as the platform is owned and maintained by Google.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will change the existing OS image being used in the cluster, to be replaced by a COS image.",
                "field_type": "impact"
            },
            {
                "field_data": "COS is Google's recommended OS for hosting and running Docker containers on Compute Engine VMs. It has a small OS footprint, which minimizes the attack surface for potential attacks. It also enables automatic updates which allow for regular patching of security vulnerabilities. Hence it is recommended that all instances belonging to GKE clusters are configured to use Container-Optimized OS (COS).",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1609"
        ]
    },
    {
        "unique_identifier": "99840092",
        "description": [
            {
                "field_data": "Not using alias IP ranging leads to more broad firewall rules being applied on services or on the VM hosting them. This means that a few services or nodes may have higher privileges than they actually require, which is leaves the cluster more exposed to a possible security breach.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will result in a new cluster being created in order to replace the old one, with alias IP ranging available.",
                "field_type": "impact"
            },
            {
                "field_data": "When alias IP ranges are enabled on a GKE cluster, a VM on which multiple services are running can assign different IP addresses from a range to every service. This is beneficial in separating the services from the infrastructure which allows the user to set up separate firewall rules for the VM's primary IP address and the alias IP addresses that belong to the services, if needed. Hence it is recommended that all GKE clusters are configured to have alias IP ranges activated.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1613"
        ]
    },
    {
        "unique_identifier": "99840093",
        "description": [
            {
                "field_data": "Not enforcing the disabling of legacy metadata APIs for clusters can potentially leave the cluster metadata vulnerable to in-transit exposure to attackers.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control creates a new node pool with legacy metadata APIs for Compute Engine disabled, which can then be used to replace the unremediated node pool.",
                "field_type": "impact"
            },
            {
                "field_data": "Legacy metadata API endpoints for Compute Engine are those belonging v0.1 and v1beta1. These endpoints do not enforce metadata query headers, leaving the endpoints exposed to potential retrieval of instance metadata by attackers. The v1 endpoints have the metadata query headers feature enforced. Hence it is recommended that all GKE clusters are configured to have legacy metadata APIs for Compute Engine disabled.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1613"
        ]
    },
    {
        "unique_identifier": "99840095",
        "description": [
            {
                "field_data": "Not enabling Master Authorized Network for a GKE cluster could possibly make it easier for attackers to interact with and access to clusters using unauthorized networks which could lead to a business loss for the organization.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will result in Authorized Master Network being enabled on the unremediated cluster, thus allowing only authorized networks to communicate with the cluster going forward.",
                "field_type": "impact"
            },
            {
                "field_data": "Master Authorized Networks is a feature that when enabled allows only authorized networks to access a GKE cluster's control plane. This improves the network security of the cluster by blocking unauthorized networks from interacting with the clusters. Hence it is recommended that all GKE clusters are configured to have Master Authorized Networks enabled.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1609"
        ]
    },
    {
        "unique_identifier": "99840096",
        "description": [
            {
                "field_data": "Not enabling a Network Policy on a cluster can lead to a much greater impact in the event of a pod getting compromised. Unrestricted pod to pod communication would lead to a much bigger loss for the organization as compared to a situation where pod to pod communication would be restricted by a network policy.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will result in pod to pod communication being restricted to authorized routes only with the use of a network policy set by the user.",
                "field_type": "impact"
            },
            {
                "field_data": "By default, pod to pod communication is enabled in a GKE cluster, allowing pods to communicate directly across nodes. A Network Policy resource is like a pod level firewall that allows only authenticated communication between pods as predetermined by the user. In case of a pod being compromised, if a Network Policy is set- it restricts the attackers from moving laterally within the cluster. Hence, it is recommended that all GKE clusters are configured to have a Network Policy enabled.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1609"
        ]
    },
    {
        "unique_identifier": "99840098",
        "description": [
            {
                "field_data": "Not making use of a CMEK prevents the client from having increased control over the behaviour of the encryption process, for example- the rotation policy of the encryption keys.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will result in the deletion of all default node pools, and them being replaced by node pools that have CMEKs enabled and configured.",
                "field_type": "impact"
            },
            {
                "field_data": "CMEK's allow for keys being used to encrypt boot disks in GKE cluster node pools to be wrapped by keys provided by Cloud KMS- thus giving the resource owner more control over access to their data. Hence it is recommended that all node pools belonging to a GKE cluster are encrypted with CMEKs.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1610"
        ]
    },
    {
        "unique_identifier": "99840099",
        "description": [
            {
                "field_data": "In case a GKE cluster is compromised and has permissions to use the default Compute Engine service account, the attackers will immediately attain the Editor role by virtue of the privilege escalation that would occur in this scenario. This could lead to a major business loss as the attackers would have access to all the data related to the project to which the service account belongs to.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will result in the creation of new node pools which will make use of a service account that has the minimum required permissions needed to operate a GKE cluster.",
                "field_type": "impact"
            },
            {
                "field_data": "By default when a GKE cluster node is created, it is assigned a IAM service account assigned to it- which is the Compute Engine default service account. This service account has very broad permissions attached to it, and using it can result in the node getting access to resources for which it does not have permissions. In order to avoid this situation of over privileged nodes, it is recommended that no GKE cluster nodes are configured to use the Compute Engine default service account.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1609"
        ]
    },
    {
        "unique_identifier": "99840102",
        "description": [
            {
                "field_data": "Using IAM roles with broad scopes can lead to a greater business loss in case the clusters that are assigned those roles are compromised, since the attackers get access to much broader permissions which can be used to compromise more services/resources.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will result in the creation of new node pools which will make use of a service account that has the minimum required permissions needed to operate a GKE cluster.",
                "field_type": "impact"
            },
            {
                "field_data": "Broad access scopes are the legacy method of providing access to resources. In order to prevent privilege escalation during an attack, service accounts with the minimum possible privilege should be to run a GKE cluster. Hence it is recommended that no GKE cluster nodes are configured to use service accounts with broad scopes.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1609"
        ]
    },
    {
        "unique_identifier": "99840103",
        "description": [
            {
                "field_data": "Using GKE clusters that have public IP addresses configured makes them discoverable over the internet, thus exposing them to communication from potential attackers.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will create a new cluster which will have the Private cluster network configuration setting enabled. This cluster can be used to replace the old unremediated cluster.",
                "field_type": "impact"
            },
            {
                "field_data": "Private clusters are those that allow their nodes to have only internal (private) IP addresses. This limits the outbound internet access for the nodes and makes them undiscoverable on the public internet, thus reducing the risk of an external attack taking place. Hence, it is recommended that all GKE clusters are configured to be Private clusters.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1613"
        ]
    },
    {
        "unique_identifier": "99840104",
        "description": [
            {
                "field_data": "Workload Identity is Google's recommended method for authentication of external entities for the usage of GCPs resources. Not using Workload Identity for GKE in order to grant access to external applications would go against Google's recommendations for best security practices.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will configure the settings in the cluster to have Workload Identity configured on newly created nodes in a cluster.",
                "field_type": "impact"
            },
            {
                "field_data": "Work Load identity is the recommended way to access Google Cloud services from within GKE. It protects some potentially sensitive metadata from user workloads running on the cluster. Hence it is recommended that all GKE clusters are configured to have Workload Identity enabled.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1609"
        ]
    },
    {
        "unique_identifier": "99840105",
        "description": [
            {
                "field_data": "Having no PodSecurityPolicy configured for the cluster could result in the deployment of a compromised node, which could be used by attackers to gain access to sensitive data.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "If the remediation of this control is performed, then a PodSecurityPolicy will be set up for the cluster. Having a PodSecurityPolicy set up for a cluster ensures that a new node can only be deployed in the cluster if it adheres to the conditions specified in the PodSecurityPolicy.",
                "field_type": "impact"
            },
            {
                "field_data": "A PodSecurityPolicy is an admission controller resource that validates requests to create and update pods on a cluster. Clusters won't accept pods that don't meet the conditions defined in the PodSecurityPolicy.When multiple PodSecurityPolicies are available, the admission controller uses the first policy that successfully validates. Policies are ordered alphabetically, and the controller prefers non-mutating policies (policies that don't change the Pod) over mutating policies.Kubernetes has officially deprecated PodSecurityPolicy in version 1.21. PodSecurityPolicy will be shut down in version 1.25.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1610"
        ]
    },
    {
        "unique_identifier": "99840106",
        "description": [
            {
                "field_data": "Enabling Alpha Cluster features will increase risk of a potential breach, which could result in major business losses for the organization as Alpha clusters expire after thirty days and do not receive security updates. We must migrate the data from alpha clusters before they expire. GKE does not automatically save data stored on alpha clusters.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "If the remediation of this control is performed then the existing cluster needs to be deleted and new cluster needs to be created.",
                "field_type": "impact"
            },
            {
                "field_data": "Alpha Cluster allows a Kubernetes cluster to make use of features that haven't yet been made generally available. They have all the GKE APIs enabled, but aren't covered by the GKE SLA. Moreover, clusters that have Alpha Cluster enabled do not receive security updates and have important features like auto-repair and auto-upgrade disabled. Hence, it is recommended that Alpha Cluster features are disabled.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1609"
        ]
    },
    {
        "unique_identifier": "99840107",
        "description": [
            {
                "field_data": "Not enabling Binary Authorization would result in a sloppy control over container environment. And remediating this control will enforce the use of images that have been signed by trusted authorities during the development process. This kind of signature based deployment allows the resource owners to gain tighter control over the container environment.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will result in binary Master Network being enabled on the unremediated cluster, thus allowing only authorized networks to communicate with the cluster going forward.",
                "field_type": "impact"
            },
            {
                "field_data": "Binary Authorization enforces the use of images that have been signed by trusted authorities during the development process. This kind of signature based deployment allows the resource owners to gain tighter control over the container environment. Hence, it is recommended that Binary Authorization is enabled for Kubernetes Clusters.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1613"
        ]
    },
    {
        "unique_identifier": "99840108",
        "description": [
            {
                "field_data": "Not enabling Application Layer Secrets will not give the benefit of 2 layered security which comes with the KMS key encryption of the Application Layer Secrets.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "If the remediation of this control is performed then it will provide extra layer of security which means only those users that have explicitly given permission to access tcan use and will not be publicly available for use.",
                "field_type": "impact"
            },
            {
                "field_data": "Application-layer secrets encryption is a feature which ensures that GKE secrets are encrypted by Cloud KMS keys, thus providing an extra layer of security. Hence it is recommended that Application-layer secrets encryption is enabled for Kubernetes clusters.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1609"
        ]
    },
    {
        "unique_identifier": "99840109",
        "description": [
            {
                "field_data": "Not making use of Shielded GKE nodes might expose the system for a vulnerability that allows attackers to exfiltrate bootstrap credentials of a Pod in order to impersonate nodes in the GKE cluster.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "If the remediation of this control is performed then Shielded GKE nodes generate about 0.5 KB more logs on startup than standard nodes.It should be notes that logs can cost result in a substantial cost for the client depending on the volume of information being stored.",
                "field_type": "impact"
            },
            {
                "field_data": "Shielded GKE nodes protects against a vulnerability that allows attackers to exfiltrate bootstrap credentials of a Pod in order to impersonate nodes in the GKE cluster. Hence it is recommended that Shielded GKE nodes is enabled for Kubernetes clusters.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1610"
        ]
    },
    {
        "unique_identifier": "99840110",
        "description": [
            {
                "field_data": "Not making use of Integrity Monitor might lead to deploying a compromised node in the pool. As Integrity Monitoring protects nodes by verifying their runtime boot integrity. Hencing saving from deploying such nodes in the pool.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control enables integrity Monitoring on the unremediated cluster. Integrity Monitoring can result in significant monetary costs for the client depending on the volume of information being consumed.",
                "field_type": "impact"
            },
            {
                "field_data": "Integrity Monitoring protects nodes by verifying their runtime boot integrity. This helps in responding to integrity failure and helps prevent compromised nodes from being deployed in the pool.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1610"
        ]
    },
    {
        "unique_identifier": "99840111",
        "description": [
            {
                "field_data": "Not making use of Intranode Visibility can result in unusual network traffic between nodes being unnoticed. This can result in a potential compromised node going unnoticed for longer, thus causing a significant business loss to the organization.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will result in additional flow logs being stored for the cluster, which can result in an additional cost related to logging.",
                "field_type": "impact"
            },
            {
                "field_data": "Enabling intranode visibility makes the intranode Pod-to-Pod traffic visible to the networking fabric. With this feature, we can use VPC flow logging or other VPC features to monitor or control intranode traffic. To get logs, we need to enable VPC flow logs in the selected subnetwork.VPC Flow Logs records a sample of network flows sent from and received by VM instances, including instances used as GKE nodes. These logs can be used for network monitoring, forensics, real-time security analysis, and expense optimization. Hence it is recommended that all GKE clusters are configured to have Workload Identity enabled.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1210"
        ]
    },
    {
        "unique_identifier": "99840112",
        "description": [
            {
                "field_data": "Disabling Secure Boot will make the GKE node open to rootkit/bootkit attacks. Remediating will protect the nodes from such threats.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the activation of Secure Boot on the remediated cluster. It is important to note that if the firmware being used in the boot configuration of a VM doesn't comply with the safety compliances of Secure Boot- it will not be allowed to boot once Secure Boot is enabled. In this case, Secure Boot will have to be disabled once so that the VM can be booted to resolve the issue- and then enabled once again.",
                "field_type": "impact"
            },
            {
                "field_data": "Secure Boot serves to protect the GKE nodes from threats such as rootkits and bootkits. A rootkit or bootkit is a collection of software that allows the attackers to gain access to resources on an instance which would not be possible under normal conditions. For instance- a root level program on the instance's operating system which would require administrator privilege under normal conditions. Hence, it is recommended that all Kubernetes clusters have Secure Boot enabled.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1053"
        ]
    },
    {
        "unique_identifier": "99840112",
        "description": [
            {
                "field_data": "Disabling Secure Boot will make the GKE node open to rootkit/bootkit attacks. Remediating will protect the nodes from such threats.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the activation of Secure Boot on the remediated cluster. It is important to note that if the firmware being used in the boot configuration of a VM doesn't comply with the safety compliances of Secure Boot- it will not be allowed to boot once Secure Boot is enabled. In this case, Secure Boot will have to be disabled once so that the VM can be booted to resolve the issue- and then enabled once again.",
                "field_type": "impact"
            },
            {
                "field_data": "Secure Boot serves to protect the GKE nodes from threats such as rootkits and bootkits. A rootkit or bootkit is a collection of software that allows the attackers to gain access to resources on an instance which would not be possible under normal conditions. For instance- a root level program on the instance's operating system which would require administrator privilege under normal conditions. Hence, it is recommended that all Kubernetes clusters have Secure Boot enabled.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1053"
        ]
    },
    {
        "unique_identifier": "99840081",
        "description": [
            {
                "field_data": "Non-organization users do not enjoy the use of security measures that Google Workspace provides for the organization's member accounts. If a non-organization member's credentials are compromised, it is likely to go undetected for longer- thus allowing for greater damage to be done to the organization's resources.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the deletion of all IAM roles that are assigned to non-organization members.",
                "field_type": "impact"
            },
            {
                "field_data": "A IAM role is a collection of permissions. Permissions determine what operations are allowed on a resource. When a user grants a role to a principal, they grant all the permissions that the role contains. IAM roles should not be assigned to users that are not using organization's credentials in order to prevent unauthorized access of sensitive information. Hence, it is recommended that no non-organization members are assigned IAM roles.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1078"
        ]
    },
    {
        "unique_identifier": "99840100",
        "description": [
            {
                "field_data": "Allowing open Google Groups accounts to be used as IAM principals in a project could potentially lead to external users gaining access to the project's resources. These external users will not be restricted by any authentication- which could be exploited by attackers to gain access to important resources resulting in a loss of data for the organization.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the deletion of all IAM roles that are assigned to open Google Groups accounts.",
                "field_type": "impact"
            },
            {
                "field_data": "An IAM policy principal for a project is an entity that is assigned an IAM role for the project. This entity can then access resources belonging to the project in accordance with the permissions contained within the IAM role assigned to it. If an open Google Groups account is allowed to maintain an IAM role for the project, any external user can gain access to this role by directly or indirectly (through a subgroup) becoming a member of the group. Hence, it is recommended that no open Google Groups account is used as an IAM policy principal.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1078"
        ]
    },
    {
        "unique_identifier": "99840114",
        "description": [
            {
                "field_data": "Making use of API keys for authentication purposes in an unrestricted manner can cause vulnerabilities that could cause loss of data due to unauthorized access. This can cause major business losses to an organization.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will result in the deletion of any API keys being used for authentication in the project. Thus, it is recommended that alternative means of authentication are set up in order to ensure continued smooth operation.",
                "field_type": "impact"
            },
            {
                "field_data": "API keys should not be used to authenticate users for a project, however end user authentication should be used instead. API keys are simple encrypted strings and do not uniquely identify users or applications making requests. Also, API keys are relatively less secure since they can be retrieved from the device they are being stored on and also be publicly viewed on a browser. Hence, it is recommended that that no API keys are used for a Project's authentication.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1552"
        ]
    },
    {
        "unique_identifier": "99840115",
        "description": [
            {
                "field_data": "If API keys are unrestricted then they can be used by anyone from anywhere and can cause vulnerabilities that could result in loss of data due to unauthorized access and affect the end-user experience resulting in a business loss for the organization.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "If the remediation of this control is performed, then the APIs and its data will be restricted to limited web sites and cannot be publicly viewed on a browser for security purposes or business reasons.",
                "field_type": "impact"
            },
            {
                "field_data": "An API key is a simple encrypted string that identifies an application without any principal. Unrestricted API keys are insecure because they can be retrieved from devices on which the key is stored or can be seen publicly, for instance, from within a browser. Hence, it is recommended that no API keys are configured to be unrestricted.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1552"
        ]
    },
    {
        "unique_identifier": "99840116",
        "description": [
            {
                "field_data": "Allowing untrusted apps to make use of API keys for authentication purposes can cause vulnerabilities which could result in loss of data and can further affect the end-user experience resulting in a business loss for the organization.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "If the remediation of this control is performed, then the API keys will be restricted and will only be fit for use by trusted apps.",
                "field_type": "impact"
            },
            {
                "field_data": "An API key is a simple encrypted string that identifies an application without any principal. API keys should only be used by trusted apps, unrestricted use of API keys by untrusted apps should be forbidden. Unrestricted API keys are insecure because they can be retrieved on devices on which the key is stored or can be seen publicly, for instance, from within a browser. Hence, it is recommended that that no API Keys are configured to be used by untrusted apps.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1552"
        ]
    },
    {
        "unique_identifier": "99840117",
        "description": [
            {
                "field_data": "If the API keys are not rotated and in use for a longer time then it increases the probability of a data breach and can cause vulnerabilities which could lead to loss of data due to unauthorized access.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "If the remediation of this control is performed, then a new API key is generated and will be available immediately and the old API key will be deactivated permanently in 24 hours.",
                "field_type": "impact"
            },
            {
                "field_data": "API keys are simple encrypted strings which do not provide the most complex level of security. API keys doesn't expire automatically, it must be manually changed by the resource owner. In order to reduce the chances of an attack succeeding, API keys should be rotated regularly. Hence it is recommended that API keys are rotated every 90 days.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1552"
        ]
    },
    {
        "unique_identifier": "99840118",
        "description": [
            {
                "field_data": "Assigning Admin, Owner and Editor roles to user created service accounts can lead to privilege escalation which could lead to user getting access to sensitive data, thus circumventing the organization's actual IAM policy for the resource that contains the sensitive data.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the deletion of all IAM roles of the type Owner, Admin or Editor that have been assigned to user created service accounts.",
                "field_type": "impact"
            },
            {
                "field_data": "No user created service accounts should be assigned the IAM roles of Admin, Owner or Editor. This is important since any user which has been granted a Service Account User role for a particular service account inherits the permissions given to the service account. This can lead to privilege escalation- allowing the access to information they should not have access to.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1078"
        ]
    },
    {
        "unique_identifier": "99840119",
        "description": [
            {
                "field_data": "In case any user's credentials are compromised, the attackers could make use of them to encrypt/decrypt sensitive data as they see fit if the user has permissions for both encryption and decryption of KMS keys. Not enforcing separation of duties greatly increases the potential damage that can be done to the organization in the event of a security breach of this kind.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the deletion of all the IAM roles that violate the principle of separation of duties pertaining to KMS. The members whose roles have been deleted may need to be assigned other roles or permissions in order to ensure continued smooth operation.",
                "field_type": "impact"
            },
            {
                "field_data": "It is recommended that no user should hold permissions for Encrypting and Decrypting KMS keys simultaneously. Furthermore, a user with the Cloud KMS Admin role shouldn't be assigned any other role. This is done so no single user has all the necessary permissions required to complete a critical business function related to KMS.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1098"
        ]
    },
    {
        "unique_identifier": "99840120",
        "description": [
            {
                "field_data": "Assigning the Service Account User/Token Creator roles across an entire project/folder/organization makes it difficult to enforce separation of duties for all the service accounts- as they all may have different permissions granted to them for different tasks. This means that if a user with such a role has their credentials compromised- the damage caused bythe breach will be much greater in magnitude as when compared to the roles being assigned for every service account separately.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the deletion of the Service Account User and Service Account Token Creator IAM roles at the project level. The members whose roles get deleted may need to be assigned IAM roles at the service account level in order to ensure continued smooth operation.",
                "field_type": "impact"
            },
            {
                "field_data": "Assigning these IAM roles to a user for the entire Project/Folder/Organization gives them permissions to use and edit every single service account in the project- presently or in the future. Instead these roles should be assigned to a user for a specific Service Account individually, if needed.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1528"
        ]
    },
    {
        "unique_identifier": "99840121",
        "description": [
            {
                "field_data": "Assigning granular roles for every use case offers more separation of duties for an organization's IAM policy, as compared to primitive roles. Using primitive roles runs the risk of there being scope for greater loss of data and disruption of services in case a user's credentials are compromised.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will result in the deletion of any primitive roles assigned to members and those roles being replaced by other less privileged roles.",
                "field_type": "impact"
            },
            {
                "field_data": "Basic roles are the Admin, Editor and Viewer roles. These roles are primitive roles that existed before the formation of IAM. The permissions related to these roles are considered too permissive, hence it is recommended that these roles are not assigned to users. Instead, more granular IAM roles are now available that allow access to individual applicabilities as need be.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1078"
        ]
    },
    {
        "unique_identifier": "99840122",
        "description": [
            {
                "field_data": "In case any user's credentials are compromised- the attackers could make use of them to extract sensitive data using the service accounts they have permissions to, as well as alter permissions provided to the service account as they see fit- if the user has permissions for a service account user and admin both. Not enforcing separation of duties greatly increases the potential damage that can be done to the organization in the event of a security breach of this kind.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the deletion of all the IAM roles that violate the principle of separation of duties pertaining to Service Accounts. The members whose roles have been deleted may need to be assigned other roles or permissions in order to ensure continued smooth operation.",
                "field_type": "impact"
            },
            {
                "field_data": "A service account is a special type of Google account intended to represent a non-human user that needs to authenticate and be authorized to access data in Google APIs. A user or service can generate external private key material (RSA) that can be used to authenticate directly to Google as the service account. This key material can then be used with Application Default Credentials (ADC) libraries, or with the gcloud auth activate-service-account command. Any person who gains access to the key material will then have full access to all resources to which the service account has access. Such private key material should be treated with the highest concern, and should be considered less secure the longer the material exists. It is recommended that a user that is assigned a Service Account Admin Role is not simultaneously assigned other roles like Service Account User. This is done so no single user has all the necessary permissions required to complete a critical business function pertaining to service accounts.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1078"
        ]
    },
    {
        "unique_identifier": "99840123",
        "description": [
            {
                "field_data": "Having audit logging disabled may reduce the organization's capability to respond swiftly to a security breach or pre-emptively iron out vulnerabilities in their security measures. This results in the potential for relatively greater loss of data and disruption of services.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "If the remediation of this control is performed then, the charges for all audit logs being stored in buckets could result in an increased storage cost for the organization.",
                "field_type": "impact"
            },
            {
                "field_data": "Audit logging enables Cloud Logging to track all admin activities, read and write access to the user's data. These audit logs can help to pre-emptively avoid loss of data by identifying vulnerabilities, hence it is recommended that audit logging is enabled.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1531"
        ]
    },
    {
        "unique_identifier": "99840124",
        "description": [
            {
                "field_data": "Assigning granular roles for every use case offers more separation of duties for an organization's IAM policy, as compared to primitive roles. Using primitive roles like the Owner role runs the risk of there being scope for greater loss of data and disruption of services in case a user's credentials are compromised. A project/folder/organization utilizing KMS keys is likely to have critical resources, which if compromised could cause a major business loss to the organization.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will result in the deletion of any unremediated IAM roles. These roles will have to be replaced by a less privileged IAM role.",
                "field_type": "impact"
            },
            {
                "field_data": "The Owner role is a basic role which has a very wide ranging list of permissions incorporated in it. A user with Owner IAM role has full edit access to every kind of resource on the project. A project protected with KMS keys is likely to have sensitive data which should not be made easy to tamper with by assigning basic roles to a user.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1496"
        ]
    },
    {
        "unique_identifier": "99840125",
        "description": [
            {
                "field_data": "Not configuring log sinks for buckets or for resources can result in the loss of data which may become critical under special circumstances and can cause a loss to an organization.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "If the remediation of this control is performed then, it could result in the increase storage of costs for the organization.",
                "field_type": "impact"
            },
            {
                "field_data": "Cloud Logging helps quickly to find the root cause of issues in system and applications. The sinks in the Log Router check each log entry against the existing inclusion filter and exclusion filters that determine which destinations, including Cloud Logging buckets, that the log entry should be sent to. Cloud Logging buckets only retain their logs for a period of 30 days. In order to make use of these logs for longer, it is recommended that they are exported and stored for a longer period of time by configuring log sinks for each bucket.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1496"
        ]
    },
    {
        "unique_identifier": "99840126",
        "description": [
            {
                "field_data": "Not enabling log metrics and alerts for Audit Configuration reduces the real time response capabilities of the organization to potential security breaches or suspicious activity. This in turn could result in a relatively larger business loss for the organization in case there is a security breach.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "If the remediation of this control is carried out, depending on the volume of activity being monitored, it can result in a significant cost related to Cloud Monitoring.",
                "field_type": "impact"
            },
            {
                "field_data": "Cloud Logging admin activity and data access logs that are used for security analysis, resource change tracking and compliance auditing. This configuration is referred to as Audit Configuration and it is recommended that log metrics and alerts are set up to monitor changes in the Cloud Logging Audit Configuration in order to monitor all the activity in the project at all times.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1496"
        ]
    },
    {
        "unique_identifier": "99840127",
        "description": [
            {
                "field_data": "Not enabling log metrics and alerts for changes in Cloud Storage permissions reduces the real time response capabilities of the organization to potential security breaches or suspicious activity. This in turn could result in a relatively larger business loss for the organization in case there is a security breach.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "If the remediation of this control is carried out, depending on the volume of activity being monitored, it can result in a significant cost related to Cloud Monitoring.",
                "field_type": "impact"
            },
            {
                "field_data": "Setting up log metrics and alerts for changes in Cloud Storage permissions for buckets can help the resource owner identify over-privileged users and suspicious activity. Hence, it is recommended that log metrics and alerts be set up for this purpose.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1530"
        ]
    },
    {
        "unique_identifier": "99840128",
        "description": [
            {
                "field_data": "Not enabling log metrics and alerts for changes in custom roles reduces the real time response capabilities of the organization to potential security breaches or suspicious activity. This in turn could result in a relatively larger business loss for the organization in case there is a security breach.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "If the remediation of this control is carried out, depending on the volume of activity being monitored, it can result in a significant cost related to Cloud Monitoring.",
                "field_type": "impact"
            },
            {
                "field_data": "IAM provides the option to create custom roles in order to access specific resources. Monitoring custom role changes can aid the early identification of overprivileged users. Hence it is recommended that log metrics and alerts are configured for custom role changes.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1078"
        ]
    },
    {
        "unique_identifier": "99840129",
        "description": [
            {
                "field_data": "Not enabling log metrics and alerts for firewall rule creation or updates reduces the real time response capabilities of the organization to potential security breaches or suspicious activity. This in turn could result in a relatively larger business loss for the organization in case there is a security breach.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "If the remediation of this control is carried out, depending on the volume of activity being monitored, it can result in a significant cost related to Cloud Monitoring.",
                "field_type": "impact"
            },
            {
                "field_data": "Monitoring firewall rule creation and updates enables the resource owner to detect suspicious activity by analyzing the network access changes for the firewalls in the project. Hence, it is recommended that log metrics and alerts are set up to monitor firewall rule changes.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1568"
        ]
    },
    {
        "unique_identifier": "99840130",
        "description": [
            {
                "field_data": "Not enabling log metrics and alerts for changes in VPC network rules reduces the real time response capabilities of the organization to potential security breaches or suspicious activity. This in turn could result in a relatively larger business loss for the organization in case there is a security breach.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "If the remediation of this control is carried out, depending on the volume of activity being monitored, it can result in a significant cost related to Cloud Monitoring.",
                "field_type": "impact"
            },
            {
                "field_data": "Monitoring network rule changes enables the resource owner to detect unauthorized changes to their networks. Hence, it is recommended that log metrics and alerts are set up to monitor network rule changes.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1590"
        ]
    },
    {
        "unique_identifier": "99840131",
        "description": [
            {
                "field_data": "Not enabling log metrics and alerts for project ownership changes reduces the real time response capabilities of the organization to potential security breaches or suspicious activity. This in turn could result in a relatively larger business loss for the organization in case there is a security breach.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "If the remediation of this control is carried out, depending on the volume of activity being monitored, it can result in a significant cost related to Cloud Monitoring.",
                "field_type": "impact"
            },
            {
                "field_data": "The Owner IAM role has the highest possible privilege available for a project. The owner of a project can delete/alter any resource belonging to that project and unauthorized access to the Owner role's permissions can cause great loss to the organization. Hence, it is recommended that log metrics and alerts are configured for ownership changes in a project.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1078"
        ]
    },
    {
        "unique_identifier": "99840132",
        "description": [
            {
                "field_data": "Not enabling log metrics and alerts for VPC network route changes reduces the real time response capabilities of the organization to potential security breaches or suspicious activity. This in turn could result in a relatively larger business loss for the organization in case there is a security breach.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "If the remediation of this control is carried out, depending on the volume of activity being monitored, it can result in a significant cost related to Cloud Monitoring.",
                "field_type": "impact"
            },
            {
                "field_data": "Network routes are the paths followed by packets when transmitted from a VM on GCP to their destination IP. Changes to the routing table can be monitored to ensure that the route does not involve unexpected paths which can compromise the communications. Hence it is recommended that log metrics and alerts are configured for VPC network route changes.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1590"
        ]
    },
    {
        "unique_identifier": "99840133",
        "description": [
            {
                "field_data": "Not enabling log metrics and alerts for changes in SQL instances reduces the real time response capabilities of the organization to potential security breaches or suspicious activity. This in turn could result in a relatively larger business loss for the organization in case there is a security breach.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "If the remediation of this control is carried out, depending on the volume of activity being monitored, it can result in a significant cost related to Cloud Monitoring.",
                "field_type": "impact"
            },
            {
                "field_data": "Misconfigurations in SQL instances can cause major security issues. Some basic changes like disabling auto backups and allowing connections to unauthorized networks can cause harm to business continuity. Hence it is recommended that log metrics and alerts are configured for Cloud SQL instance changes.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1596"
        ]
    },
    {
        "unique_identifier": "99840134",
        "description": [
            {
                "field_data": "Default network firewall rules do not meet the required network security standards for an organization, and thus may leave the projects relatively vulnerable to attacks that could result in a loss of sensitive data.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will result in the deletion of any default VPN networks in the project. The deleted network will have to be replaced by the freshly created network mentioned in the remediation step wherever it was being employed to prevent any application/production services from breaking.",
                "field_type": "impact"
            },
            {
                "field_data": "A default network is one that is automatically created when a project is created, with pre-populated firewall rules and network configurations, which may not comply with the configurations required to ensure the network security of the project. Hence it is recommended that no default networks are used in a GCP project.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1046"
        ]
    },
    {
        "unique_identifier": "99840135",
        "description": [
            {
                "field_data": "Legacy networks not supporting subnetting leads to a more inefficient networking configuration for a project. Using legacy networks is disadvantageous for an organization from the view point of practicality and making use of the latest Google Cloud Networking features.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will result in the deletion of any legacy VPN networks in the project. The user needs to replace the deleted network with the freshly created network mentioned in the remediation step wherever it was being employed to prevent any application/production services from breaking.",
                "field_type": "impact"
            },
            {
                "field_data": "Legacy Networks are networks that use a single global IP range that cannot be divided into subnets. Instances with IP addresses belonging to a legacy network cannot be grouped by region or zone. Legacy networks do not support some of the latest Google Cloud Networking features. Hence it is recommended that no legacy networks should be used in a GCP Project.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1046"
        ]
    },
    {
        "unique_identifier": "99840136",
        "description": [
            {
                "field_data": "Having dns logging disabled may reduce the organization's capability to respond swiftly to a security breach or pre-emptively iron out vulnerabilities in their security measures. This results in the potential for relatively greater loss of data and disruption of services.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "If the remediation of this control is performed then, the charges for all dns logs being stored could result in an increased storage cost for the organization.",
                "field_type": "impact"
            },
            {
                "field_data": "Monitoring of Cloud DNS logs provides visibility to DNS names requested by the clients within the VPC network. These logs can be monitored for anomalous domain names and evaluated against threat intelligence. We recommend enabling DNS logging for VPC networks. Hence it is recommended that dns logging is enabled.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1590"
        ]
    },
    {
        "unique_identifier": "99840137",
        "description": [
            {
                "field_data": "Not enabling DNSSEC for Cloud DNS managed zones leaves them more susceptible to DNS hijacking and man-in-the-middle attacks which could lead to systems being compromised and rendered unfit for use.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "If the remediation of this control is performed then the DNS resolver systems interacting with the managed zone will have to be updated with a new key-signing-key(KSK). This will provide a strong authentication framework (but not encryption) for domain lookups.",
                "field_type": "impact"
            },
            {
                "field_data": "The Domain Name System Security Extensions (DNSSEC) is a feature of the Domain Name System (DNS) that authenticates responses to domain name lookups. It does not provide privacy protections for those lookups, but prevents attackers from manipulating or poisoning the responses to DNS requests. Enabling DNSSEC reduces risk of DNS hijacking and man-in-the-middle attacks.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1110"
        ]
    },
    {
        "unique_identifier": "99840138",
        "description": [
            {
                "field_data": "Using RSASHA1 algorithms for key-signing results increases the chances of an attack succeeding and resulting in unauthorized access to the resource. This also increases the probability of a business loss occurring for the organization.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "If the remediation of this control is performed, all the RSASHA1 algorithms being used in the managed zone will be replaced by SHA256 key signing algorithms.",
                "field_type": "impact"
            },
            {
                "field_data": "RSASHA1 algorithms do not provide adequate security for key signing purposes in a DNS Managed Zone- especially for keys with larger key lengths. When enabling DNSSEC for a managed zone, or creating a managed zone with DNSSEC, we can select the DNSSEC signing algorithms and the denial-of-existence type. It is recommended that stronger algorithms are employed for this purpose (like RSASHA256).",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1110"
        ]
    },
    {
        "unique_identifier": "99840139",
        "description": [
            {
                "field_data": "If Cloud KMS encryption keys being used for authentication purposes are not rotated at regular intervals, it can cause vulnerabilities that could result in loss of data due to unauthorized access. This can cause major business losses to an organization.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "If the remediation of this control is performed then, a new key is generated and will be available immediately and the old key will be deactivated.",
                "field_type": "impact"
            },
            {
                "field_data": "Cloud KMS encryption keys should be rotated regularly in order to reduce the amount of encrypted messages available to attackers for cryptoanalysis for a specific key version. Regular rotation limits the number of actual messages vulnerable to compromise. Hence it is recommended that Cloud KMS encryption keys are rotated every 90 days. If a key version is under suspicion of being compromised, disable it and revoke access to it as soon as possible.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1552"
        ]
    },
    {
        "unique_identifier": "99840140",
        "description": [
            {
                "field_data": "In case of encryption key or keyring being publicly accessible, the sensitive data in the instance can be misused by an attacker to leak critical information, which may result in a business loss for the organization.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead encryption key or keyring being accessible to only those users that have explicitly given permission to access them through an IAM role and will not be publicly available for use.",
                "field_type": "impact"
            },
            {
                "field_data": "Having a Cloud KMS key public makes it freely accessible to all IP addresses. This can have serious ramifications for the privacy of the resource that the KMS key is being used for, leading to unauthorized access of data. This means that users which do not belong to the parent organization can gain access to the resource, which can lead to loss of data. Thus, no encryption key or keyring should be publicly accessible.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1565"
        ]
    },
    {
        "unique_identifier": "99840141",
        "description": [
            {
                "field_data": "By having more than three principal users for a key, the attack surface for attackers to potentially gain complete control over a key's operations is made larger than necessary. This increases the risk of a potential breach, which could result in major business losses for the organization through unauthorized access to the resources being encrypted by the key in question.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "If the remediation of this control is performed then, it could disrupt the production environment because removing some roles or permission will affect the services.",
                "field_type": "impact"
            },
            {
                "field_data": "A principal user is one which has permissions required to encrypt, decrypt or sign data using a cryptographic key. It is recommended that not more than three users are assigned such roles to a particular key. The predefined IAM roles considered principal users are- owner, cryptoKeyEncrypterDecrypter, cryptoKeyEncrypter, cryptoKeyDecrypter, signer and signerVerifier.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1565"
        ]
    },
    {
        "unique_identifier": "99840140",
        "description": [
            {
                "field_data": "In case of encryption key or keyring being publicly accessible, the sensitive data in the instance can be misused by an attacker to leak critical information, which may result in a business loss for the organization.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead encryption key or keyring being accessible to only those users that have explicitly given permission to access them through an IAM role and will not be publicly available for use.",
                "field_type": "impact"
            },
            {
                "field_data": "Having a Cloud KMS key public makes it freely accessible to all IP addresses. This can have serious ramifications for the privacy of the resource that the KMS key is being used for, leading to unauthorized access of data. This means that users which do not belong to the parent organization can gain access to the resource, which can lead to loss of data. Thus, no encryption key or keyring should be publicly accessible.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1565"
        ]
    },
    {
        "unique_identifier": "99840038",
        "description": [
            {
                "field_data": "Location restriction Organization policies are not enforced retroactively on already existing resources. This means that already existing resources that violate these policies will not be deleted/altered since there might be operational pitfalls as a result of taking such an action.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control can have major operational repercussion, and should be carried out only if crucial services are not being impacted critically.",
                "field_type": "impact"
            },
            {
                "field_data": "Organization policies can be set up to create restrictions on resources being assigned to certain regions. It limit the physical location of a new resource with the Organization Policy Service resource locations constraint. It can use the location property of a resource to identify where it is deployed and maintained by the service. For data-containing resources of some Google Cloud services, this property also reflects the location where data is stored. This constraint allows us to define the allowed Google Cloud locations where the resources for supported services in the hierarchy can be created. These policies should not be violated by individual resources if the restrictions are enforced with important business constraints in mind. Hence it is recommended that all instances are configured to comply with location restriction Organization policies.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1535"
        ]
    },
    {
        "unique_identifier": "99840142",
        "description": [
            {
                "field_data": "Not making use of a CMEK prevents the client from having increased control over the behaviour of the encryption process, for example- the rotation policy of the encryption keys.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control results in the encryption of assets with customer managed keys as opposed to Google's default encryption-at-rest facility. This may result in an additional cost to the customer.",
                "field_type": "impact"
            },
            {
                "field_data": "CMEKs are customer managed keys that provide an extra layer of encryption over Google's standard data at rest encryption. CMEKs allow for keys being used in Compute Instance disks to be wrapped by keys provided by Cloud KMS- thus giving the resource owner more control over access to their data. Hence, it is recommended that all Compute Engine instance disks have Customer-Managed Encryption Keys (CMEKs) enabled.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1592"
        ]
    },
    {
        "unique_identifier": "99840143",
        "description": [
            {
                "field_data": "Not making use of CSEK takes away an additional layer of protection from the encryption process.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the use of CSEKs on the remediated asset. Use of CSEKs may incur an additional cost to the client as compared to Google's default encryption-at-rest.",
                "field_type": "impact"
            },
            {
                "field_data": "Customer-Supplied Encryption Keys (CSEK) are a feature in Google Cloud Storage and Google Compute Engine. If we supply our own encryption keys, Google uses the key to protect the Google-generated keys used to encrypt and decrypt the data.It allows for keys provided by the resource owner to protect the Google-generated keys being used to encrypt and decrypt data in the Compute Instance disk. This results in a more robust security.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1592"
        ]
    },
    {
        "unique_identifier": "99840038",
        "description": [
            {
                "field_data": "Location restriction Organization policies are not enforced retroactively on already existing resources. This means that already existing resources that violate these policies will not be deleted/altered since there might be operational pitfalls as a result of taking such an action.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control can have major operational repercussion, and should be carried out only if crucial services are not being impacted critically.",
                "field_type": "impact"
            },
            {
                "field_data": "Organization policies can be set up to create restrictions on resources being assigned to certain regions. It limit the physical location of a new resource with the Organization Policy Service resource locations constraint. It can use the location property of a resource to identify where it is deployed and maintained by the service. For data-containing resources of some Google Cloud services, this property also reflects the location where data is stored. This constraint allows us to define the allowed Google Cloud locations where the resources for supported services in the hierarchy can be created. These policies should not be violated by individual resources if the restrictions are enforced with important business constraints in mind. Hence it is recommended that all instances are configured to comply with location restriction Organization policies.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1535"
        ]
    },
    {
        "unique_identifier": "99840144",
        "description": [
            {
                "field_data": "If Customer Managed Encryption Keys (CMEKs) are not used, then the user will not have full control over data encryption and decryption process, while increasing the probability of the data being leaked to an attacker- resulting in a business loss for the organization.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "If the remediation of this control is performed then the previous topic will be deleted and a new topic will be created using Customer Managed Encryption Keys (CMEKs) for its encryption, which are chargeable and will get added to the bill.",
                "field_type": "impact"
            },
            {
                "field_data": "Pub/Sub stands for Publisher/Subscriber which allows services to communicate asynchronously, with latencies on the order of 100 milliseconds. It is used for streaming analytics and data integration pipelines to ingest and distribute data. CMEKs allow keys being used in Pub/Sub topics to be wrapped by keys provided by Cloud KMS thus giving the resource owner more control over access to their data. So, it is recommended that all Cloud Pub/Sub topics have Customer-Managed Encryption Keys (CMEKs) enabled.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1600"
        ]
    },
    {
        "unique_identifier": "99840081",
        "description": [
            {
                "field_data": "Non-organization users do not enjoy the use of security measures that Google Workspace provides for the organization's member accounts. If a non-organization member's credentials are compromised, it is likely to go undetected for longer- thus allowing for greater damage to be done to the organization's resources.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the deletion of all IAM roles that are assigned to non-organization members.",
                "field_type": "impact"
            },
            {
                "field_data": "A IAM role is a collection of permissions. Permissions determine what operations are allowed on a resource. When a user grants a role to a principal, they grant all the permissions that the role contains. IAM roles should not be assigned to users that are not using organization's credentials in order to prevent unauthorized access of sensitive information. Hence, it is recommended that no non-organization members are assigned IAM roles.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1078"
        ]
    },
    {
        "unique_identifier": "99840094",
        "description": [
            {
                "field_data": "Not enforcing MFA leaves the organization more vulnerable to unauthorized access through compromised user user login credentials. Detecting such a security breach is more complicated than taking steps to prevent it by enforcing MFA.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will result in the enforcement of MFA in the organization. Users will have to set up MFA the next time they attempt to log in.",
                "field_type": "impact"
            },
            {
                "field_data": "MFA, specifically 2-Step Verification is an important tool to protect against compromised login credentials. Hence, it is recommended that it is enabled for all users in the Organization.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1586"
        ]
    },
    {
        "unique_identifier": "99840100",
        "description": [
            {
                "field_data": "Allowing open Google Groups accounts to be used as IAM principals in a project could potentially lead to external users gaining access to the project's resources. These external users will not be restricted by any authentication- which could be exploited by attackers to gain access to important resources resulting in a loss of data for the organization.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the deletion of all IAM roles that are assigned to open Google Groups accounts.",
                "field_type": "impact"
            },
            {
                "field_data": "An IAM policy principal for a project is an entity that is assigned an IAM role for the project. This entity can then access resources belonging to the project in accordance with the permissions contained within the IAM role assigned to it. If an open Google Groups account is allowed to maintain an IAM role for the project, any external user can gain access to this role by directly or indirectly (through a subgroup) becoming a member of the group. Hence, it is recommended that no open Google Groups account is used as an IAM policy principal.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1078"
        ]
    },
    {
        "unique_identifier": "99840118",
        "description": [
            {
                "field_data": "Assigning Admin, Owner and Editor roles to user created service accounts can lead to privilege escalation which could lead to user getting access to sensitive data, thus circumventing the organization's actual IAM policy for the resource that contains the sensitive data.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the deletion of all IAM roles of the type Owner, Admin or Editor that have been assigned to user created service accounts.",
                "field_type": "impact"
            },
            {
                "field_data": "No user created service accounts should be assigned the IAM roles of Admin, Owner or Editor. This is important since any user which has been granted a Service Account User role for a particular service account inherits the permissions given to the service account. This can lead to privilege escalation- allowing the access to information they should not have access to.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1078"
        ]
    },
    {
        "unique_identifier": "99840119",
        "description": [
            {
                "field_data": "In case any user's credentials are compromised, the attackers could make use of them to encrypt/decrypt sensitive data as they see fit if the user has permissions for both encryption and decryption of KMS keys. Not enforcing separation of duties greatly increases the potential damage that can be done to the organization in the event of a security breach of this kind.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the deletion of all the IAM roles that violate the principle of separation of duties pertaining to KMS. The members whose roles have been deleted may need to be assigned other roles or permissions in order to ensure continued smooth operation.",
                "field_type": "impact"
            },
            {
                "field_data": "It is recommended that no user should hold permissions for Encrypting and Decrypting KMS keys simultaneously. Furthermore, a user with the Cloud KMS Admin role shouldn't be assigned any other role. This is done so no single user has all the necessary permissions required to complete a critical business function related to KMS.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1098"
        ]
    },
    {
        "unique_identifier": "99840120",
        "description": [
            {
                "field_data": "Assigning the Service Account User/Token Creator roles across an entire project/folder/organization makes it difficult to enforce separation of duties for all the service accounts- as they all may have different permissions granted to them for different tasks. This means that if a user with such a role has their credentials compromised- the damage caused bythe breach will be much greater in magnitude as when compared to the roles being assigned for every service account separately.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the deletion of the Service Account User and Service Account Token Creator IAM roles at the project level. The members whose roles get deleted may need to be assigned IAM roles at the service account level in order to ensure continued smooth operation.",
                "field_type": "impact"
            },
            {
                "field_data": "Assigning these IAM roles to a user for the entire Project/Folder/Organization gives them permissions to use and edit every single service account in the project- presently or in the future. Instead these roles should be assigned to a user for a specific Service Account individually, if needed.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1528"
        ]
    },
    {
        "unique_identifier": "99840121",
        "description": [
            {
                "field_data": "Assigning granular roles for every use case offers more separation of duties for an organization's IAM policy, as compared to primitive roles. Using primitive roles runs the risk of there being scope for greater loss of data and disruption of services in case a user's credentials are compromised.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will result in the deletion of any primitive roles assigned to members and those roles being replaced by other less privileged roles.",
                "field_type": "impact"
            },
            {
                "field_data": "Basic roles are the Admin, Editor and Viewer roles. These roles are primitive roles that existed before the formation of IAM. The permissions related to these roles are considered too permissive, hence it is recommended that these roles are not assigned to users. Instead, more granular IAM roles are now available that allow access to individual applicabilities as need be.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1078"
        ]
    },
    {
        "unique_identifier": "99840122",
        "description": [
            {
                "field_data": "In case any user's credentials are compromised- the attackers could make use of them to extract sensitive data using the service accounts they have permissions to, as well as alter permissions provided to the service account as they see fit- if the user has permissions for a service account user and admin both. Not enforcing separation of duties greatly increases the potential damage that can be done to the organization in the event of a security breach of this kind.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the deletion of all the IAM roles that violate the principle of separation of duties pertaining to Service Accounts. The members whose roles have been deleted may need to be assigned other roles or permissions in order to ensure continued smooth operation.",
                "field_type": "impact"
            },
            {
                "field_data": "A service account is a special type of Google account intended to represent a non-human user that needs to authenticate and be authorized to access data in Google APIs. A user or service can generate external private key material (RSA) that can be used to authenticate directly to Google as the service account. This key material can then be used with Application Default Credentials (ADC) libraries, or with the gcloud auth activate-service-account command. Any person who gains access to the key material will then have full access to all resources to which the service account has access. Such private key material should be treated with the highest concern, and should be considered less secure the longer the material exists. It is recommended that a user that is assigned a Service Account Admin Role is not simultaneously assigned other roles like Service Account User. This is done so no single user has all the necessary permissions required to complete a critical business function pertaining to service accounts.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1078"
        ]
    },
    {
        "unique_identifier": "99840123",
        "description": [
            {
                "field_data": "Having audit logging disabled may reduce the organization's capability to respond swiftly to a security breach or pre-emptively iron out vulnerabilities in their security measures. This results in the potential for relatively greater loss of data and disruption of services.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "If the remediation of this control is performed then, the charges for all audit logs being stored in buckets could result in an increased storage cost for the organization.",
                "field_type": "impact"
            },
            {
                "field_data": "Audit logging enables Cloud Logging to track all admin activities, read and write access to the user's data. These audit logs can help to pre-emptively avoid loss of data by identifying vulnerabilities, hence it is recommended that audit logging is enabled.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1531"
        ]
    },
    {
        "unique_identifier": "99840145",
        "description": [
            {
                "field_data": "Assigning REDIS related IAM roles at the Organization level could lead to attackers gaining access to every REDIS resource in the organization in case a user's credentials are compromised- as compared to gaining access to a single project's resources if the roles are assigned at the project level.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will result in the deletion of any REDIS related IAM roles at the organization/folder level- which will then have to be replaced by new roles at the project level.",
                "field_type": "impact"
            },
            {
                "field_data": "Memorystore for Redis provides a set of predefined roles designed to help the user easily control access to the Redis resources. REDIS IAM roles- redis.admin, redis.editor, redis.viewer when assigned at the organization/folder level could result in accidental privilege escalation. Hence it is recommended that no user is assigned a REDIS related IAM role at the Organization/Folder level, but at the project level instead.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1078"
        ]
    },
    {
        "unique_identifier": "99840081",
        "description": [
            {
                "field_data": "Non-organization users do not enjoy the use of security measures that Google Workspace provides for the organization's member accounts. If a non-organization member's credentials are compromised, it is likely to go undetected for longer- thus allowing for greater damage to be done to the organization's resources.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the deletion of all IAM roles that are assigned to non-organization members.",
                "field_type": "impact"
            },
            {
                "field_data": "A IAM role is a collection of permissions. Permissions determine what operations are allowed on a resource. When a user grants a role to a principal, they grant all the permissions that the role contains. IAM roles should not be assigned to users that are not using organization's credentials in order to prevent unauthorized access of sensitive information. Hence, it is recommended that no non-organization members are assigned IAM roles.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1078"
        ]
    },
    {
        "unique_identifier": "99840100",
        "description": [
            {
                "field_data": "Allowing open Google Groups accounts to be used as IAM principals in a project could potentially lead to external users gaining access to the project's resources. These external users will not be restricted by any authentication- which could be exploited by attackers to gain access to important resources resulting in a loss of data for the organization.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the deletion of all IAM roles that are assigned to open Google Groups accounts.",
                "field_type": "impact"
            },
            {
                "field_data": "An IAM policy principal for a project is an entity that is assigned an IAM role for the project. This entity can then access resources belonging to the project in accordance with the permissions contained within the IAM role assigned to it. If an open Google Groups account is allowed to maintain an IAM role for the project, any external user can gain access to this role by directly or indirectly (through a subgroup) becoming a member of the group. Hence, it is recommended that no open Google Groups account is used as an IAM policy principal.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1078"
        ]
    },
    {
        "unique_identifier": "99840118",
        "description": [
            {
                "field_data": "Assigning Admin, Owner and Editor roles to user created service accounts can lead to privilege escalation which could lead to user getting access to sensitive data, thus circumventing the organization's actual IAM policy for the resource that contains the sensitive data.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the deletion of all IAM roles of the type Owner, Admin or Editor that have been assigned to user created service accounts.",
                "field_type": "impact"
            },
            {
                "field_data": "No user created service accounts should be assigned the IAM roles of Admin, Owner or Editor. This is important since any user which has been granted a Service Account User role for a particular service account inherits the permissions given to the service account. This can lead to privilege escalation- allowing the access to information they should not have access to.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1078"
        ]
    },
    {
        "unique_identifier": "99840119",
        "description": [
            {
                "field_data": "In case any user's credentials are compromised, the attackers could make use of them to encrypt/decrypt sensitive data as they see fit if the user has permissions for both encryption and decryption of KMS keys. Not enforcing separation of duties greatly increases the potential damage that can be done to the organization in the event of a security breach of this kind.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the deletion of all the IAM roles that violate the principle of separation of duties pertaining to KMS. The members whose roles have been deleted may need to be assigned other roles or permissions in order to ensure continued smooth operation.",
                "field_type": "impact"
            },
            {
                "field_data": "It is recommended that no user should hold permissions for Encrypting and Decrypting KMS keys simultaneously. Furthermore, a user with the Cloud KMS Admin role shouldn't be assigned any other role. This is done so no single user has all the necessary permissions required to complete a critical business function related to KMS.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1098"
        ]
    },
    {
        "unique_identifier": "99840120",
        "description": [
            {
                "field_data": "Assigning the Service Account User/Token Creator roles across an entire project/folder/organization makes it difficult to enforce separation of duties for all the service accounts- as they all may have different permissions granted to them for different tasks. This means that if a user with such a role has their credentials compromised- the damage caused bythe breach will be much greater in magnitude as when compared to the roles being assigned for every service account separately.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the deletion of the Service Account User and Service Account Token Creator IAM roles at the project level. The members whose roles get deleted may need to be assigned IAM roles at the service account level in order to ensure continued smooth operation.",
                "field_type": "impact"
            },
            {
                "field_data": "Assigning these IAM roles to a user for the entire Project/Folder/Organization gives them permissions to use and edit every single service account in the project- presently or in the future. Instead these roles should be assigned to a user for a specific Service Account individually, if needed.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1528"
        ]
    },
    {
        "unique_identifier": "99840121",
        "description": [
            {
                "field_data": "Assigning granular roles for every use case offers more separation of duties for an organization's IAM policy, as compared to primitive roles. Using primitive roles runs the risk of there being scope for greater loss of data and disruption of services in case a user's credentials are compromised.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will result in the deletion of any primitive roles assigned to members and those roles being replaced by other less privileged roles.",
                "field_type": "impact"
            },
            {
                "field_data": "Basic roles are the Admin, Editor and Viewer roles. These roles are primitive roles that existed before the formation of IAM. The permissions related to these roles are considered too permissive, hence it is recommended that these roles are not assigned to users. Instead, more granular IAM roles are now available that allow access to individual applicabilities as need be.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1078"
        ]
    },
    {
        "unique_identifier": "99840122",
        "description": [
            {
                "field_data": "In case any user's credentials are compromised- the attackers could make use of them to extract sensitive data using the service accounts they have permissions to, as well as alter permissions provided to the service account as they see fit- if the user has permissions for a service account user and admin both. Not enforcing separation of duties greatly increases the potential damage that can be done to the organization in the event of a security breach of this kind.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the deletion of all the IAM roles that violate the principle of separation of duties pertaining to Service Accounts. The members whose roles have been deleted may need to be assigned other roles or permissions in order to ensure continued smooth operation.",
                "field_type": "impact"
            },
            {
                "field_data": "A service account is a special type of Google account intended to represent a non-human user that needs to authenticate and be authorized to access data in Google APIs. A user or service can generate external private key material (RSA) that can be used to authenticate directly to Google as the service account. This key material can then be used with Application Default Credentials (ADC) libraries, or with the gcloud auth activate-service-account command. Any person who gains access to the key material will then have full access to all resources to which the service account has access. Such private key material should be treated with the highest concern, and should be considered less secure the longer the material exists. It is recommended that a user that is assigned a Service Account Admin Role is not simultaneously assigned other roles like Service Account User. This is done so no single user has all the necessary permissions required to complete a critical business function pertaining to service accounts.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1078"
        ]
    },
    {
        "unique_identifier": "99840123",
        "description": [
            {
                "field_data": "Having audit logging disabled may reduce the organization's capability to respond swiftly to a security breach or pre-emptively iron out vulnerabilities in their security measures. This results in the potential for relatively greater loss of data and disruption of services.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "If the remediation of this control is performed then, the charges for all audit logs being stored in buckets could result in an increased storage cost for the organization.",
                "field_type": "impact"
            },
            {
                "field_data": "Audit logging enables Cloud Logging to track all admin activities, read and write access to the user's data. These audit logs can help to pre-emptively avoid loss of data by identifying vulnerabilities, hence it is recommended that audit logging is enabled.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1531"
        ]
    },
    {
        "unique_identifier": "99840038",
        "description": [
            {
                "field_data": "Location restriction Organization policies are not enforced retroactively on already existing resources. This means that already existing resources that violate these policies will not be deleted/altered since there might be operational pitfalls as a result of taking such an action.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control can have major operational repercussion, and should be carried out only if crucial services are not being impacted critically.",
                "field_type": "impact"
            },
            {
                "field_data": "Organization policies can be set up to create restrictions on resources being assigned to certain regions. It limit the physical location of a new resource with the Organization Policy Service resource locations constraint. It can use the location property of a resource to identify where it is deployed and maintained by the service. For data-containing resources of some Google Cloud services, this property also reflects the location where data is stored. This constraint allows us to define the allowed Google Cloud locations where the resources for supported services in the hierarchy can be created. These policies should not be violated by individual resources if the restrictions are enforced with important business constraints in mind. Hence it is recommended that all instances are configured to comply with location restriction Organization policies.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1535"
        ]
    },
    {
        "unique_identifier": "99840097",
        "description": [
            {
                "field_data": "If Compute Engine images are publicly accessible to anyone on the internet then it can expose sensitive information like encryption keys or licensed softwares and this information can be used by attackers to gain unauthorized access to VMs that have used the image which can lead to business loss for the organization in the form of loss of sensitive data.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to compute engine images being accessible to only those users that have explicitly given permission to access them through an IAM role by the removal of all role assignments provided to allUsers and allAuthenticatedUsers.",
                "field_type": "impact"
            },
            {
                "field_data": "Compute Engine images should not be accessible to everyone on the internet in order to protect sensitive information regarding Compute Engine resources. Hence, it is recommended that Compute Engine images are not publicly accessible.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1592"
        ]
    },
    {
        "unique_identifier": "99840038",
        "description": [
            {
                "field_data": "Location restriction Organization policies are not enforced retroactively on already existing resources. This means that already existing resources that violate these policies will not be deleted/altered since there might be operational pitfalls as a result of taking such an action.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control can have major operational repercussion, and should be carried out only if crucial services are not being impacted critically.",
                "field_type": "impact"
            },
            {
                "field_data": "Organization policies can be set up to create restrictions on resources being assigned to certain regions. It limit the physical location of a new resource with the Organization Policy Service resource locations constraint. It can use the location property of a resource to identify where it is deployed and maintained by the service. For data-containing resources of some Google Cloud services, this property also reflects the location where data is stored. This constraint allows us to define the allowed Google Cloud locations where the resources for supported services in the hierarchy can be created. These policies should not be violated by individual resources if the restrictions are enforced with important business constraints in mind. Hence it is recommended that all instances are configured to comply with location restriction Organization policies.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1535"
        ]
    },
    {
        "unique_identifier": "99840101",
        "description": [
            {
                "field_data": "Using Dataproc cluster images that can be exploited using Log4j vulnerabilities can potentially lead to attackers gaining control of log messages or log message parameters on the cluster. In this case, under certain circumstances an attacker would be able to upload and execute malicious code loaded from an LDAP (Lightweight Directory Access Protocol) server.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "Google strongly recommends deleting the cluster that fails this control and replacing it with a new cluster with an updated image version. This remediation process could result in a disruption of the production environment and the services making use of this cluster if the recreation process is not carried out correctly.",
                "field_type": "impact"
            },
            {
                "field_data": "Dataproc clusters are Apache image based clusters that can be impacted by the Log4j related security vulnerabilities CVE-2021-44228 and CVE-2021-45046. This control penalizes the use of those Dataproc image versions that had been affected by these vulnerabilites, namely any image version earlier than 1.3.95 or any subminor image version earlier than 1.4.77, 1.5.53, or 2.0.27.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1203"
        ]
    },
    {
        "unique_identifier": "99840146",
        "description": [
            {
                "field_data": "Not enabling OS login and using metadata based SSH management is less makes the client's Compute VM instances more vulnerable. OS Login can be configured to be used with MFA, while metadata based SSH management cannot be.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will enable OS Login and enforce centralized SSH key management on the remediated VM instance. After OS Login is enabled on one or more instances in a project, those VMs accept connections only from user accounts that have the necessary IAM roles in the project or organization (for instance- roles/compute.osLogin).",
                "field_type": "impact"
            },
            {
                "field_data": "OS Login enables centralized SSH key management using IAM while also disabling meta-data based SSH key management on a Compute Engine instance. OS Login can be enabled or disabled by setting metadata values at the instance or project level. Enabling or disabling OS Login in instance metadata overrides the value that is set in project metadata.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1552"
        ]
    },
    {
        "unique_identifier": "99840038",
        "description": [
            {
                "field_data": "Location restriction Organization policies are not enforced retroactively on already existing resources. This means that already existing resources that violate these policies will not be deleted/altered since there might be operational pitfalls as a result of taking such an action.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control can have major operational repercussion, and should be carried out only if crucial services are not being impacted critically.",
                "field_type": "impact"
            },
            {
                "field_data": "Organization policies can be set up to create restrictions on resources being assigned to certain regions. It limit the physical location of a new resource with the Organization Policy Service resource locations constraint. It can use the location property of a resource to identify where it is deployed and maintained by the service. For data-containing resources of some Google Cloud services, this property also reflects the location where data is stored. This constraint allows us to define the allowed Google Cloud locations where the resources for supported services in the hierarchy can be created. These policies should not be violated by individual resources if the restrictions are enforced with important business constraints in mind. Hence it is recommended that all instances are configured to comply with location restriction Organization policies.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1535"
        ]
    },
    {
        "unique_identifier": "99840038",
        "description": [
            {
                "field_data": "Location restriction Organization policies are not enforced retroactively on already existing resources. This means that already existing resources that violate these policies will not be deleted/altered since there might be operational pitfalls as a result of taking such an action.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control can have major operational repercussion, and should be carried out only if crucial services are not being impacted critically.",
                "field_type": "impact"
            },
            {
                "field_data": "Organization policies can be set up to create restrictions on resources being assigned to certain regions. It limit the physical location of a new resource with the Organization Policy Service resource locations constraint. It can use the location property of a resource to identify where it is deployed and maintained by the service. For data-containing resources of some Google Cloud services, this property also reflects the location where data is stored. This constraint allows us to define the allowed Google Cloud locations where the resources for supported services in the hierarchy can be created. These policies should not be violated by individual resources if the restrictions are enforced with important business constraints in mind. Hence it is recommended that all instances are configured to comply with location restriction Organization policies.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1535"
        ]
    },
    {
        "unique_identifier": "99840148",
        "description": [
            {
                "field_data": "By default, VMs that do not have a public IP address assigned to them can only send packets to destinations within the private network of GCP resources, hence they can not communicate with public Google APIs.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will allow VMs that do not have a public IP address to communicate with public Google APIs in order make use of them in their application's functioning.",
                "field_type": "impact"
            },
            {
                "field_data": "Compute Engine VM lacks an external IP address assigned to its network interface, it can only send packets to other internal IP address destinations. It can allow these VMs to connect to the set of external IP addresses used by Google APIs and services by enabling Private Google Access on the subnet used by the VM's network interface. Private Google Access enables VMs that have only private IP addresses to interact with the public Google APIs. Hence, it is recommended that all private subnetworks have Private Google Access Enabled.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1590"
        ]
    },
    {
        "unique_identifier": "99840038",
        "description": [
            {
                "field_data": "Location restriction Organization policies are not enforced retroactively on already existing resources. This means that already existing resources that violate these policies will not be deleted/altered since there might be operational pitfalls as a result of taking such an action.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control can have major operational repercussion, and should be carried out only if crucial services are not being impacted critically.",
                "field_type": "impact"
            },
            {
                "field_data": "Organization policies can be set up to create restrictions on resources being assigned to certain regions. It limit the physical location of a new resource with the Organization Policy Service resource locations constraint. It can use the location property of a resource to identify where it is deployed and maintained by the service. For data-containing resources of some Google Cloud services, this property also reflects the location where data is stored. This constraint allows us to define the allowed Google Cloud locations where the resources for supported services in the hierarchy can be created. These policies should not be violated by individual resources if the restrictions are enforced with important business constraints in mind. Hence it is recommended that all instances are configured to comply with location restriction Organization policies.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1535"
        ]
    },
    {
        "unique_identifier": "99840149",
        "description": [
            {
                "field_data": "Using a target HTTP proxy as opposed to a target HTTPS proxy load balancer leads to a less secure configuration for the network communication that the VM participates in. Unencrypted communication can potentially lead to the messages being intercepted- which could lead to a loss of data for the organization.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the deletion of all HTTP proxies related to a load balancer. The deleted configurations might need to be replaced by configurations that allow only HTTPS traffic in order to prevent applications or services from breaking.",
                "field_type": "impact"
            },
            {
                "field_data": "If a VM is making use of a Load Balancer- the Load Balancer should be configured to only allow HTTPS connections, and not HTTP connections in order to improve security of network communication.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1557"
        ]
    },
    {
        "unique_identifier": "99840038",
        "description": [
            {
                "field_data": "Location restriction Organization policies are not enforced retroactively on already existing resources. This means that already existing resources that violate these policies will not be deleted/altered since there might be operational pitfalls as a result of taking such an action.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control can have major operational repercussion, and should be carried out only if crucial services are not being impacted critically.",
                "field_type": "impact"
            },
            {
                "field_data": "Organization policies can be set up to create restrictions on resources being assigned to certain regions. It limit the physical location of a new resource with the Organization Policy Service resource locations constraint. It can use the location property of a resource to identify where it is deployed and maintained by the service. For data-containing resources of some Google Cloud services, this property also reflects the location where data is stored. This constraint allows us to define the allowed Google Cloud locations where the resources for supported services in the hierarchy can be created. These policies should not be violated by individual resources if the restrictions are enforced with important business constraints in mind. Hence it is recommended that all instances are configured to comply with location restriction Organization policies.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1535"
        ]
    },
    {
        "unique_identifier": "99840152",
        "description": [
            {
                "field_data": "A weak SSL policy takes away the protection provided by the latest version of TLS and a secure cipher suite. It can result in a malicious actor decrypting data containing sensitive information, potentially leading to a complete compromise of confidentiality and integrity which can lead to unauthorized access to a VM- thus leading to the loss of data associated with that VM.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control replaces any weak SSL policy configured in the remediated VM instance with an SSL policy which makes use of the latest version of TLS and a secure cipher suite.",
                "field_type": "impact"
            },
            {
                "field_data": "SSL stands for Secure Sockets Layer and is used for keeping an internet connection secure and safeguarding any sensitive data that is being sent between two systems, preventing criminals from reading and modifying any information transferred, including potential personal details. A weak SSL policy is one which allows a client to connect to the instance with an outdated version of TLS- which might be using a less secure cipher suite or protocol. It is recommended to enforce the use of the latest version of TLS, along with a secure cipher suite.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1588"
        ]
    },
    {
        "unique_identifier": "99840152",
        "description": [
            {
                "field_data": "A weak SSL policy takes away the protection provided by the latest version of TLS and a secure cipher suite. It can result in a malicious actor decrypting data containing sensitive information, potentially leading to a complete compromise of confidentiality and integrity which can lead to unauthorized access to a VM- thus leading to the loss of data associated with that VM.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control replaces any weak SSL policy configured in the remediated VM instance with an SSL policy which makes use of the latest version of TLS and a secure cipher suite.",
                "field_type": "impact"
            },
            {
                "field_data": "SSL stands for Secure Sockets Layer and is used for keeping an internet connection secure and safeguarding any sensitive data that is being sent between two systems, preventing criminals from reading and modifying any information transferred, including potential personal details. A weak SSL policy is one which allows a client to connect to the instance with an outdated version of TLS- which might be using a less secure cipher suite or protocol. It is recommended to enforce the use of the latest version of TLS, along with a secure cipher suite.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1588"
        ]
    },
    {
        "unique_identifier": "99840136",
        "description": [
            {
                "field_data": "Having dns logging disabled may reduce the organization's capability to respond swiftly to a security breach or pre-emptively iron out vulnerabilities in their security measures. This results in the potential for relatively greater loss of data and disruption of services.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "If the remediation of this control is performed then, the charges for all dns logs being stored could result in an increased storage cost for the organization.",
                "field_type": "impact"
            },
            {
                "field_data": "Monitoring of Cloud DNS logs provides visibility to DNS names requested by the clients within the VPC network. These logs can be monitored for anomalous domain names and evaluated against threat intelligence. We recommend enabling DNS logging for VPC networks. Hence it is recommended that dns logging is enabled.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1590"
        ]
    },
    {
        "unique_identifier": "99840150",
        "description": [
            {
                "field_data": "If user managed service account keys being used for authentication purposes are not rotated at regular intervals, it can cause vulnerabilities that could cause loss of data due to unauthorized access. This can cause major business losses to an organization.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the deletion of the unremediated service account key- which will then have to be replaced by a freshly generated new service account key. The old key will have to be manually replaced by the new one wherever it was being used in the production environment in order to ensure continued smooth operation.",
                "field_type": "impact"
            },
            {
                "field_data": "A service account is a special type of Google account intended to represent a non-human user that needs to authenticate and be authorized to access data in Google APIs. Any person who gains access to the service account key material will then have full access to all resources to which the service account has access. Such private key material should be treated with the highest concern, and should be considered less secure the longer the material exists. User managed service account keys should be rotated regularly in order to reduce the risk of an older key being compromised which could lead to a loss of data. Hence it is recommended that service account keys are rotated every 90 days.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1552"
        ]
    },
    {
        "unique_identifier": "99840151",
        "description": [
            {
                "field_data": "Using user managed service account keys runs the risk of the organization being more vulnerable to a potential security breach involving a service account. A security breach like this involving a service account with high level permissions may result in a major business loss for the organization.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control will lead to the deletion of the unremediated service account key- which will then have to be replaced by a freshly generated new service account key. The old key will have to be manually replaced by the new one wherever it was being used in the production environment in order to ensure continued smooth operation.",
                "field_type": "impact"
            },
            {
                "field_data": "A service account is a special type of Google account intended to represent a non-human user that needs to authenticate and be authorized to access data in Google APIs. Any person who gains access to the service account key material will then have full access to all resources to which the service account has access. Such private key material should be treated with the highest concern, and should be considered less secure the longer the material exists. User managed service account keys should not be used unless absolutely unavoidable. This is because user managed keys are more susceptible to being compromised which increases the likelihood of loss of data or unauthorized access. Hence it is recommended that service account keys are not configured to be user managed.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1552"
        ]
    },
    {
        "unique_identifier": "99840038",
        "description": [
            {
                "field_data": "Location restriction Organization policies are not enforced retroactively on already existing resources. This means that already existing resources that violate these policies will not be deleted/altered since there might be operational pitfalls as a result of taking such an action.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control can have major operational repercussion, and should be carried out only if crucial services are not being impacted critically.",
                "field_type": "impact"
            },
            {
                "field_data": "Organization policies can be set up to create restrictions on resources being assigned to certain regions. It limit the physical location of a new resource with the Organization Policy Service resource locations constraint. It can use the location property of a resource to identify where it is deployed and maintained by the service. For data-containing resources of some Google Cloud services, this property also reflects the location where data is stored. This constraint allows us to define the allowed Google Cloud locations where the resources for supported services in the hierarchy can be created. These policies should not be violated by individual resources if the restrictions are enforced with important business constraints in mind. Hence it is recommended that all instances are configured to comply with location restriction Organization policies.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1535"
        ]
    },
    {
        "unique_identifier": "99840038",
        "description": [
            {
                "field_data": "Location restriction Organization policies are not enforced retroactively on already existing resources. This means that already existing resources that violate these policies will not be deleted/altered since there might be operational pitfalls as a result of taking such an action.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control can have major operational repercussion, and should be carried out only if crucial services are not being impacted critically.",
                "field_type": "impact"
            },
            {
                "field_data": "Organization policies can be set up to create restrictions on resources being assigned to certain regions. It limit the physical location of a new resource with the Organization Policy Service resource locations constraint. It can use the location property of a resource to identify where it is deployed and maintained by the service. For data-containing resources of some Google Cloud services, this property also reflects the location where data is stored. This constraint allows us to define the allowed Google Cloud locations where the resources for supported services in the hierarchy can be created. These policies should not be violated by individual resources if the restrictions are enforced with important business constraints in mind. Hence it is recommended that all instances are configured to comply with location restriction Organization policies.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1535"
        ]
    },
    {
        "unique_identifier": "99840038",
        "description": [
            {
                "field_data": "Location restriction Organization policies are not enforced retroactively on already existing resources. This means that already existing resources that violate these policies will not be deleted/altered since there might be operational pitfalls as a result of taking such an action.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control can have major operational repercussion, and should be carried out only if crucial services are not being impacted critically.",
                "field_type": "impact"
            },
            {
                "field_data": "Organization policies can be set up to create restrictions on resources being assigned to certain regions. It limit the physical location of a new resource with the Organization Policy Service resource locations constraint. It can use the location property of a resource to identify where it is deployed and maintained by the service. For data-containing resources of some Google Cloud services, this property also reflects the location where data is stored. This constraint allows us to define the allowed Google Cloud locations where the resources for supported services in the hierarchy can be created. These policies should not be violated by individual resources if the restrictions are enforced with important business constraints in mind. Hence it is recommended that all instances are configured to comply with location restriction Organization policies.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1535"
        ]
    },
    {
        "unique_identifier": "99840038",
        "description": [
            {
                "field_data": "Location restriction Organization policies are not enforced retroactively on already existing resources. This means that already existing resources that violate these policies will not be deleted/altered since there might be operational pitfalls as a result of taking such an action.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control can have major operational repercussion, and should be carried out only if crucial services are not being impacted critically.",
                "field_type": "impact"
            },
            {
                "field_data": "Organization policies can be set up to create restrictions on resources being assigned to certain regions. It limit the physical location of a new resource with the Organization Policy Service resource locations constraint. It can use the location property of a resource to identify where it is deployed and maintained by the service. For data-containing resources of some Google Cloud services, this property also reflects the location where data is stored. This constraint allows us to define the allowed Google Cloud locations where the resources for supported services in the hierarchy can be created. These policies should not be violated by individual resources if the restrictions are enforced with important business constraints in mind. Hence it is recommended that all instances are configured to comply with location restriction Organization policies.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1535"
        ]
    },
    {
        "unique_identifier": "99840038",
        "description": [
            {
                "field_data": "Location restriction Organization policies are not enforced retroactively on already existing resources. This means that already existing resources that violate these policies will not be deleted/altered since there might be operational pitfalls as a result of taking such an action.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control can have major operational repercussion, and should be carried out only if crucial services are not being impacted critically.",
                "field_type": "impact"
            },
            {
                "field_data": "Organization policies can be set up to create restrictions on resources being assigned to certain regions. It limit the physical location of a new resource with the Organization Policy Service resource locations constraint. It can use the location property of a resource to identify where it is deployed and maintained by the service. For data-containing resources of some Google Cloud services, this property also reflects the location where data is stored. This constraint allows us to define the allowed Google Cloud locations where the resources for supported services in the hierarchy can be created. These policies should not be violated by individual resources if the restrictions are enforced with important business constraints in mind. Hence it is recommended that all instances are configured to comply with location restriction Organization policies.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1535"
        ]
    },
    {
        "unique_identifier": "99840038",
        "description": [
            {
                "field_data": "Location restriction Organization policies are not enforced retroactively on already existing resources. This means that already existing resources that violate these policies will not be deleted/altered since there might be operational pitfalls as a result of taking such an action.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control can have major operational repercussion, and should be carried out only if crucial services are not being impacted critically.",
                "field_type": "impact"
            },
            {
                "field_data": "Organization policies can be set up to create restrictions on resources being assigned to certain regions. It limit the physical location of a new resource with the Organization Policy Service resource locations constraint. It can use the location property of a resource to identify where it is deployed and maintained by the service. For data-containing resources of some Google Cloud services, this property also reflects the location where data is stored. This constraint allows us to define the allowed Google Cloud locations where the resources for supported services in the hierarchy can be created. These policies should not be violated by individual resources if the restrictions are enforced with important business constraints in mind. Hence it is recommended that all instances are configured to comply with location restriction Organization policies.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1535"
        ]
    },
    {
        "unique_identifier": "99840038",
        "description": [
            {
                "field_data": "Location restriction Organization policies are not enforced retroactively on already existing resources. This means that already existing resources that violate these policies will not be deleted/altered since there might be operational pitfalls as a result of taking such an action.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control can have major operational repercussion, and should be carried out only if crucial services are not being impacted critically.",
                "field_type": "impact"
            },
            {
                "field_data": "Organization policies can be set up to create restrictions on resources being assigned to certain regions. It limit the physical location of a new resource with the Organization Policy Service resource locations constraint. It can use the location property of a resource to identify where it is deployed and maintained by the service. For data-containing resources of some Google Cloud services, this property also reflects the location where data is stored. This constraint allows us to define the allowed Google Cloud locations where the resources for supported services in the hierarchy can be created. These policies should not be violated by individual resources if the restrictions are enforced with important business constraints in mind. Hence it is recommended that all instances are configured to comply with location restriction Organization policies.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1535"
        ]
    },
    {
        "unique_identifier": "99840038",
        "description": [
            {
                "field_data": "Location restriction Organization policies are not enforced retroactively on already existing resources. This means that already existing resources that violate these policies will not be deleted/altered since there might be operational pitfalls as a result of taking such an action.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control can have major operational repercussion, and should be carried out only if crucial services are not being impacted critically.",
                "field_type": "impact"
            },
            {
                "field_data": "Organization policies can be set up to create restrictions on resources being assigned to certain regions. It limit the physical location of a new resource with the Organization Policy Service resource locations constraint. It can use the location property of a resource to identify where it is deployed and maintained by the service. For data-containing resources of some Google Cloud services, this property also reflects the location where data is stored. This constraint allows us to define the allowed Google Cloud locations where the resources for supported services in the hierarchy can be created. These policies should not be violated by individual resources if the restrictions are enforced with important business constraints in mind. Hence it is recommended that all instances are configured to comply with location restriction Organization policies.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1535"
        ]
    },
    {
        "unique_identifier": "99840038",
        "description": [
            {
                "field_data": "Location restriction Organization policies are not enforced retroactively on already existing resources. This means that already existing resources that violate these policies will not be deleted/altered since there might be operational pitfalls as a result of taking such an action.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control can have major operational repercussion, and should be carried out only if crucial services are not being impacted critically.",
                "field_type": "impact"
            },
            {
                "field_data": "Organization policies can be set up to create restrictions on resources being assigned to certain regions. It limit the physical location of a new resource with the Organization Policy Service resource locations constraint. It can use the location property of a resource to identify where it is deployed and maintained by the service. For data-containing resources of some Google Cloud services, this property also reflects the location where data is stored. This constraint allows us to define the allowed Google Cloud locations where the resources for supported services in the hierarchy can be created. These policies should not be violated by individual resources if the restrictions are enforced with important business constraints in mind. Hence it is recommended that all instances are configured to comply with location restriction Organization policies.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1535"
        ]
    },
    {
        "unique_identifier": "99840038",
        "description": [
            {
                "field_data": "Location restriction Organization policies are not enforced retroactively on already existing resources. This means that already existing resources that violate these policies will not be deleted/altered since there might be operational pitfalls as a result of taking such an action.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control can have major operational repercussion, and should be carried out only if crucial services are not being impacted critically.",
                "field_type": "impact"
            },
            {
                "field_data": "Organization policies can be set up to create restrictions on resources being assigned to certain regions. It limit the physical location of a new resource with the Organization Policy Service resource locations constraint. It can use the location property of a resource to identify where it is deployed and maintained by the service. For data-containing resources of some Google Cloud services, this property also reflects the location where data is stored. This constraint allows us to define the allowed Google Cloud locations where the resources for supported services in the hierarchy can be created. These policies should not be violated by individual resources if the restrictions are enforced with important business constraints in mind. Hence it is recommended that all instances are configured to comply with location restriction Organization policies.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1535"
        ]
    },
    {
        "unique_identifier": "99840038",
        "description": [
            {
                "field_data": "Location restriction Organization policies are not enforced retroactively on already existing resources. This means that already existing resources that violate these policies will not be deleted/altered since there might be operational pitfalls as a result of taking such an action.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control can have major operational repercussion, and should be carried out only if crucial services are not being impacted critically.",
                "field_type": "impact"
            },
            {
                "field_data": "Organization policies can be set up to create restrictions on resources being assigned to certain regions. It limit the physical location of a new resource with the Organization Policy Service resource locations constraint. It can use the location property of a resource to identify where it is deployed and maintained by the service. For data-containing resources of some Google Cloud services, this property also reflects the location where data is stored. This constraint allows us to define the allowed Google Cloud locations where the resources for supported services in the hierarchy can be created. These policies should not be violated by individual resources if the restrictions are enforced with important business constraints in mind. Hence it is recommended that all instances are configured to comply with location restriction Organization policies.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1535"
        ]
    },
    {
        "unique_identifier": "99840038",
        "description": [
            {
                "field_data": "Location restriction Organization policies are not enforced retroactively on already existing resources. This means that already existing resources that violate these policies will not be deleted/altered since there might be operational pitfalls as a result of taking such an action.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control can have major operational repercussion, and should be carried out only if crucial services are not being impacted critically.",
                "field_type": "impact"
            },
            {
                "field_data": "Organization policies can be set up to create restrictions on resources being assigned to certain regions. It limit the physical location of a new resource with the Organization Policy Service resource locations constraint. It can use the location property of a resource to identify where it is deployed and maintained by the service. For data-containing resources of some Google Cloud services, this property also reflects the location where data is stored. This constraint allows us to define the allowed Google Cloud locations where the resources for supported services in the hierarchy can be created. These policies should not be violated by individual resources if the restrictions are enforced with important business constraints in mind. Hence it is recommended that all instances are configured to comply with location restriction Organization policies.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1535"
        ]
    },
    {
        "unique_identifier": "99840038",
        "description": [
            {
                "field_data": "Location restriction Organization policies are not enforced retroactively on already existing resources. This means that already existing resources that violate these policies will not be deleted/altered since there might be operational pitfalls as a result of taking such an action.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control can have major operational repercussion, and should be carried out only if crucial services are not being impacted critically.",
                "field_type": "impact"
            },
            {
                "field_data": "Organization policies can be set up to create restrictions on resources being assigned to certain regions. It limit the physical location of a new resource with the Organization Policy Service resource locations constraint. It can use the location property of a resource to identify where it is deployed and maintained by the service. For data-containing resources of some Google Cloud services, this property also reflects the location where data is stored. This constraint allows us to define the allowed Google Cloud locations where the resources for supported services in the hierarchy can be created. These policies should not be violated by individual resources if the restrictions are enforced with important business constraints in mind. Hence it is recommended that all instances are configured to comply with location restriction Organization policies.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1535"
        ]
    },
    {
        "unique_identifier": "99840038",
        "description": [
            {
                "field_data": "Location restriction Organization policies are not enforced retroactively on already existing resources. This means that already existing resources that violate these policies will not be deleted/altered since there might be operational pitfalls as a result of taking such an action.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control can have major operational repercussion, and should be carried out only if crucial services are not being impacted critically.",
                "field_type": "impact"
            },
            {
                "field_data": "Organization policies can be set up to create restrictions on resources being assigned to certain regions. It limit the physical location of a new resource with the Organization Policy Service resource locations constraint. It can use the location property of a resource to identify where it is deployed and maintained by the service. For data-containing resources of some Google Cloud services, this property also reflects the location where data is stored. This constraint allows us to define the allowed Google Cloud locations where the resources for supported services in the hierarchy can be created. These policies should not be violated by individual resources if the restrictions are enforced with important business constraints in mind. Hence it is recommended that all instances are configured to comply with location restriction Organization policies.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1535"
        ]
    },
    {
        "unique_identifier": "99840038",
        "description": [
            {
                "field_data": "Location restriction Organization policies are not enforced retroactively on already existing resources. This means that already existing resources that violate these policies will not be deleted/altered since there might be operational pitfalls as a result of taking such an action.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control can have major operational repercussion, and should be carried out only if crucial services are not being impacted critically.",
                "field_type": "impact"
            },
            {
                "field_data": "Organization policies can be set up to create restrictions on resources being assigned to certain regions. It limit the physical location of a new resource with the Organization Policy Service resource locations constraint. It can use the location property of a resource to identify where it is deployed and maintained by the service. For data-containing resources of some Google Cloud services, this property also reflects the location where data is stored. This constraint allows us to define the allowed Google Cloud locations where the resources for supported services in the hierarchy can be created. These policies should not be violated by individual resources if the restrictions are enforced with important business constraints in mind. Hence it is recommended that all instances are configured to comply with location restriction Organization policies.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1535"
        ]
    },
    {
        "unique_identifier": "99840038",
        "description": [
            {
                "field_data": "Location restriction Organization policies are not enforced retroactively on already existing resources. This means that already existing resources that violate these policies will not be deleted/altered since there might be operational pitfalls as a result of taking such an action.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control can have major operational repercussion, and should be carried out only if crucial services are not being impacted critically.",
                "field_type": "impact"
            },
            {
                "field_data": "Organization policies can be set up to create restrictions on resources being assigned to certain regions. It limit the physical location of a new resource with the Organization Policy Service resource locations constraint. It can use the location property of a resource to identify where it is deployed and maintained by the service. For data-containing resources of some Google Cloud services, this property also reflects the location where data is stored. This constraint allows us to define the allowed Google Cloud locations where the resources for supported services in the hierarchy can be created. These policies should not be violated by individual resources if the restrictions are enforced with important business constraints in mind. Hence it is recommended that all instances are configured to comply with location restriction Organization policies.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1535"
        ]
    },
    {
        "unique_identifier": "99840038",
        "description": [
            {
                "field_data": "Location restriction Organization policies are not enforced retroactively on already existing resources. This means that already existing resources that violate these policies will not be deleted/altered since there might be operational pitfalls as a result of taking such an action.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control can have major operational repercussion, and should be carried out only if crucial services are not being impacted critically.",
                "field_type": "impact"
            },
            {
                "field_data": "Organization policies can be set up to create restrictions on resources being assigned to certain regions. It limit the physical location of a new resource with the Organization Policy Service resource locations constraint. It can use the location property of a resource to identify where it is deployed and maintained by the service. For data-containing resources of some Google Cloud services, this property also reflects the location where data is stored. This constraint allows us to define the allowed Google Cloud locations where the resources for supported services in the hierarchy can be created. These policies should not be violated by individual resources if the restrictions are enforced with important business constraints in mind. Hence it is recommended that all instances are configured to comply with location restriction Organization policies.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1535"
        ]
    },
    {
        "unique_identifier": "99840038",
        "description": [
            {
                "field_data": "Location restriction Organization policies are not enforced retroactively on already existing resources. This means that already existing resources that violate these policies will not be deleted/altered since there might be operational pitfalls as a result of taking such an action.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control can have major operational repercussion, and should be carried out only if crucial services are not being impacted critically.",
                "field_type": "impact"
            },
            {
                "field_data": "Organization policies can be set up to create restrictions on resources being assigned to certain regions. It limit the physical location of a new resource with the Organization Policy Service resource locations constraint. It can use the location property of a resource to identify where it is deployed and maintained by the service. For data-containing resources of some Google Cloud services, this property also reflects the location where data is stored. This constraint allows us to define the allowed Google Cloud locations where the resources for supported services in the hierarchy can be created. These policies should not be violated by individual resources if the restrictions are enforced with important business constraints in mind. Hence it is recommended that all instances are configured to comply with location restriction Organization policies.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1535"
        ]
    },
    {
        "unique_identifier": "99840038",
        "description": [
            {
                "field_data": "Location restriction Organization policies are not enforced retroactively on already existing resources. This means that already existing resources that violate these policies will not be deleted/altered since there might be operational pitfalls as a result of taking such an action.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control can have major operational repercussion, and should be carried out only if crucial services are not being impacted critically.",
                "field_type": "impact"
            },
            {
                "field_data": "Organization policies can be set up to create restrictions on resources being assigned to certain regions. It limit the physical location of a new resource with the Organization Policy Service resource locations constraint. It can use the location property of a resource to identify where it is deployed and maintained by the service. For data-containing resources of some Google Cloud services, this property also reflects the location where data is stored. This constraint allows us to define the allowed Google Cloud locations where the resources for supported services in the hierarchy can be created. These policies should not be violated by individual resources if the restrictions are enforced with important business constraints in mind. Hence it is recommended that all instances are configured to comply with location restriction Organization policies.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1535"
        ]
    },
    {
        "unique_identifier": "99840038",
        "description": [
            {
                "field_data": "Location restriction Organization policies are not enforced retroactively on already existing resources. This means that already existing resources that violate these policies will not be deleted/altered since there might be operational pitfalls as a result of taking such an action.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control can have major operational repercussion, and should be carried out only if crucial services are not being impacted critically.",
                "field_type": "impact"
            },
            {
                "field_data": "Organization policies can be set up to create restrictions on resources being assigned to certain regions. It limit the physical location of a new resource with the Organization Policy Service resource locations constraint. It can use the location property of a resource to identify where it is deployed and maintained by the service. For data-containing resources of some Google Cloud services, this property also reflects the location where data is stored. This constraint allows us to define the allowed Google Cloud locations where the resources for supported services in the hierarchy can be created. These policies should not be violated by individual resources if the restrictions are enforced with important business constraints in mind. Hence it is recommended that all instances are configured to comply with location restriction Organization policies.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1535"
        ]
    },
    {
        "unique_identifier": "99840038",
        "description": [
            {
                "field_data": "Location restriction Organization policies are not enforced retroactively on already existing resources. This means that already existing resources that violate these policies will not be deleted/altered since there might be operational pitfalls as a result of taking such an action.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control can have major operational repercussion, and should be carried out only if crucial services are not being impacted critically.",
                "field_type": "impact"
            },
            {
                "field_data": "Organization policies can be set up to create restrictions on resources being assigned to certain regions. It limit the physical location of a new resource with the Organization Policy Service resource locations constraint. It can use the location property of a resource to identify where it is deployed and maintained by the service. For data-containing resources of some Google Cloud services, this property also reflects the location where data is stored. This constraint allows us to define the allowed Google Cloud locations where the resources for supported services in the hierarchy can be created. These policies should not be violated by individual resources if the restrictions are enforced with important business constraints in mind. Hence it is recommended that all instances are configured to comply with location restriction Organization policies.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1535"
        ]
    },
    {
        "unique_identifier": "99840038",
        "description": [
            {
                "field_data": "Location restriction Organization policies are not enforced retroactively on already existing resources. This means that already existing resources that violate these policies will not be deleted/altered since there might be operational pitfalls as a result of taking such an action.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control can have major operational repercussion, and should be carried out only if crucial services are not being impacted critically.",
                "field_type": "impact"
            },
            {
                "field_data": "Organization policies can be set up to create restrictions on resources being assigned to certain regions. It limit the physical location of a new resource with the Organization Policy Service resource locations constraint. It can use the location property of a resource to identify where it is deployed and maintained by the service. For data-containing resources of some Google Cloud services, this property also reflects the location where data is stored. This constraint allows us to define the allowed Google Cloud locations where the resources for supported services in the hierarchy can be created. These policies should not be violated by individual resources if the restrictions are enforced with important business constraints in mind. Hence it is recommended that all instances are configured to comply with location restriction Organization policies.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1535"
        ]
    },
    {
        "unique_identifier": "99840038",
        "description": [
            {
                "field_data": "Location restriction Organization policies are not enforced retroactively on already existing resources. This means that already existing resources that violate these policies will not be deleted/altered since there might be operational pitfalls as a result of taking such an action.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control can have major operational repercussion, and should be carried out only if crucial services are not being impacted critically.",
                "field_type": "impact"
            },
            {
                "field_data": "Organization policies can be set up to create restrictions on resources being assigned to certain regions. It limit the physical location of a new resource with the Organization Policy Service resource locations constraint. It can use the location property of a resource to identify where it is deployed and maintained by the service. For data-containing resources of some Google Cloud services, this property also reflects the location where data is stored. This constraint allows us to define the allowed Google Cloud locations where the resources for supported services in the hierarchy can be created. These policies should not be violated by individual resources if the restrictions are enforced with important business constraints in mind. Hence it is recommended that all instances are configured to comply with location restriction Organization policies.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1535"
        ]
    },
    {
        "unique_identifier": "99840038",
        "description": [
            {
                "field_data": "Location restriction Organization policies are not enforced retroactively on already existing resources. This means that already existing resources that violate these policies will not be deleted/altered since there might be operational pitfalls as a result of taking such an action.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control can have major operational repercussion, and should be carried out only if crucial services are not being impacted critically.",
                "field_type": "impact"
            },
            {
                "field_data": "Organization policies can be set up to create restrictions on resources being assigned to certain regions. It limit the physical location of a new resource with the Organization Policy Service resource locations constraint. It can use the location property of a resource to identify where it is deployed and maintained by the service. For data-containing resources of some Google Cloud services, this property also reflects the location where data is stored. This constraint allows us to define the allowed Google Cloud locations where the resources for supported services in the hierarchy can be created. These policies should not be violated by individual resources if the restrictions are enforced with important business constraints in mind. Hence it is recommended that all instances are configured to comply with location restriction Organization policies.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1535"
        ]
    },
    {
        "unique_identifier": "99840038",
        "description": [
            {
                "field_data": "Location restriction Organization policies are not enforced retroactively on already existing resources. This means that already existing resources that violate these policies will not be deleted/altered since there might be operational pitfalls as a result of taking such an action.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control can have major operational repercussion, and should be carried out only if crucial services are not being impacted critically.",
                "field_type": "impact"
            },
            {
                "field_data": "Organization policies can be set up to create restrictions on resources being assigned to certain regions. It limit the physical location of a new resource with the Organization Policy Service resource locations constraint. It can use the location property of a resource to identify where it is deployed and maintained by the service. For data-containing resources of some Google Cloud services, this property also reflects the location where data is stored. This constraint allows us to define the allowed Google Cloud locations where the resources for supported services in the hierarchy can be created. These policies should not be violated by individual resources if the restrictions are enforced with important business constraints in mind. Hence it is recommended that all instances are configured to comply with location restriction Organization policies.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1535"
        ]
    },
    {
        "unique_identifier": "99840038",
        "description": [
            {
                "field_data": "Location restriction Organization policies are not enforced retroactively on already existing resources. This means that already existing resources that violate these policies will not be deleted/altered since there might be operational pitfalls as a result of taking such an action.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control can have major operational repercussion, and should be carried out only if crucial services are not being impacted critically.",
                "field_type": "impact"
            },
            {
                "field_data": "Organization policies can be set up to create restrictions on resources being assigned to certain regions. It limit the physical location of a new resource with the Organization Policy Service resource locations constraint. It can use the location property of a resource to identify where it is deployed and maintained by the service. For data-containing resources of some Google Cloud services, this property also reflects the location where data is stored. This constraint allows us to define the allowed Google Cloud locations where the resources for supported services in the hierarchy can be created. These policies should not be violated by individual resources if the restrictions are enforced with important business constraints in mind. Hence it is recommended that all instances are configured to comply with location restriction Organization policies.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1535"
        ]
    },
    {
        "unique_identifier": "99840038",
        "description": [
            {
                "field_data": "Location restriction Organization policies are not enforced retroactively on already existing resources. This means that already existing resources that violate these policies will not be deleted/altered since there might be operational pitfalls as a result of taking such an action.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control can have major operational repercussion, and should be carried out only if crucial services are not being impacted critically.",
                "field_type": "impact"
            },
            {
                "field_data": "Organization policies can be set up to create restrictions on resources being assigned to certain regions. It limit the physical location of a new resource with the Organization Policy Service resource locations constraint. It can use the location property of a resource to identify where it is deployed and maintained by the service. For data-containing resources of some Google Cloud services, this property also reflects the location where data is stored. This constraint allows us to define the allowed Google Cloud locations where the resources for supported services in the hierarchy can be created. These policies should not be violated by individual resources if the restrictions are enforced with important business constraints in mind. Hence it is recommended that all instances are configured to comply with location restriction Organization policies.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1535"
        ]
    },
    {
        "unique_identifier": "99840038",
        "description": [
            {
                "field_data": "Location restriction Organization policies are not enforced retroactively on already existing resources. This means that already existing resources that violate these policies will not be deleted/altered since there might be operational pitfalls as a result of taking such an action.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control can have major operational repercussion, and should be carried out only if crucial services are not being impacted critically.",
                "field_type": "impact"
            },
            {
                "field_data": "Organization policies can be set up to create restrictions on resources being assigned to certain regions. It limit the physical location of a new resource with the Organization Policy Service resource locations constraint. It can use the location property of a resource to identify where it is deployed and maintained by the service. For data-containing resources of some Google Cloud services, this property also reflects the location where data is stored. This constraint allows us to define the allowed Google Cloud locations where the resources for supported services in the hierarchy can be created. These policies should not be violated by individual resources if the restrictions are enforced with important business constraints in mind. Hence it is recommended that all instances are configured to comply with location restriction Organization policies.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1535"
        ]
    },
    {
        "unique_identifier": "99840038",
        "description": [
            {
                "field_data": "Location restriction Organization policies are not enforced retroactively on already existing resources. This means that already existing resources that violate these policies will not be deleted/altered since there might be operational pitfalls as a result of taking such an action.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control can have major operational repercussion, and should be carried out only if crucial services are not being impacted critically.",
                "field_type": "impact"
            },
            {
                "field_data": "Organization policies can be set up to create restrictions on resources being assigned to certain regions. It limit the physical location of a new resource with the Organization Policy Service resource locations constraint. It can use the location property of a resource to identify where it is deployed and maintained by the service. For data-containing resources of some Google Cloud services, this property also reflects the location where data is stored. This constraint allows us to define the allowed Google Cloud locations where the resources for supported services in the hierarchy can be created. These policies should not be violated by individual resources if the restrictions are enforced with important business constraints in mind. Hence it is recommended that all instances are configured to comply with location restriction Organization policies.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1535"
        ]
    },
    {
        "unique_identifier": "99840038",
        "description": [
            {
                "field_data": "Location restriction Organization policies are not enforced retroactively on already existing resources. This means that already existing resources that violate these policies will not be deleted/altered since there might be operational pitfalls as a result of taking such an action.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control can have major operational repercussion, and should be carried out only if crucial services are not being impacted critically.",
                "field_type": "impact"
            },
            {
                "field_data": "Organization policies can be set up to create restrictions on resources being assigned to certain regions. It limit the physical location of a new resource with the Organization Policy Service resource locations constraint. It can use the location property of a resource to identify where it is deployed and maintained by the service. For data-containing resources of some Google Cloud services, this property also reflects the location where data is stored. This constraint allows us to define the allowed Google Cloud locations where the resources for supported services in the hierarchy can be created. These policies should not be violated by individual resources if the restrictions are enforced with important business constraints in mind. Hence it is recommended that all instances are configured to comply with location restriction Organization policies.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1535"
        ]
    },
    {
        "unique_identifier": "99840038",
        "description": [
            {
                "field_data": "Location restriction Organization policies are not enforced retroactively on already existing resources. This means that already existing resources that violate these policies will not be deleted/altered since there might be operational pitfalls as a result of taking such an action.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control can have major operational repercussion, and should be carried out only if crucial services are not being impacted critically.",
                "field_type": "impact"
            },
            {
                "field_data": "Organization policies can be set up to create restrictions on resources being assigned to certain regions. It limit the physical location of a new resource with the Organization Policy Service resource locations constraint. It can use the location property of a resource to identify where it is deployed and maintained by the service. For data-containing resources of some Google Cloud services, this property also reflects the location where data is stored. This constraint allows us to define the allowed Google Cloud locations where the resources for supported services in the hierarchy can be created. These policies should not be violated by individual resources if the restrictions are enforced with important business constraints in mind. Hence it is recommended that all instances are configured to comply with location restriction Organization policies.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1535"
        ]
    },
    {
        "unique_identifier": "99840038",
        "description": [
            {
                "field_data": "Location restriction Organization policies are not enforced retroactively on already existing resources. This means that already existing resources that violate these policies will not be deleted/altered since there might be operational pitfalls as a result of taking such an action.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control can have major operational repercussion, and should be carried out only if crucial services are not being impacted critically.",
                "field_type": "impact"
            },
            {
                "field_data": "Organization policies can be set up to create restrictions on resources being assigned to certain regions. It limit the physical location of a new resource with the Organization Policy Service resource locations constraint. It can use the location property of a resource to identify where it is deployed and maintained by the service. For data-containing resources of some Google Cloud services, this property also reflects the location where data is stored. This constraint allows us to define the allowed Google Cloud locations where the resources for supported services in the hierarchy can be created. These policies should not be violated by individual resources if the restrictions are enforced with important business constraints in mind. Hence it is recommended that all instances are configured to comply with location restriction Organization policies.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1535"
        ]
    },
    {
        "unique_identifier": "99840038",
        "description": [
            {
                "field_data": "Location restriction Organization policies are not enforced retroactively on already existing resources. This means that already existing resources that violate these policies will not be deleted/altered since there might be operational pitfalls as a result of taking such an action.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control can have major operational repercussion, and should be carried out only if crucial services are not being impacted critically.",
                "field_type": "impact"
            },
            {
                "field_data": "Organization policies can be set up to create restrictions on resources being assigned to certain regions. It limit the physical location of a new resource with the Organization Policy Service resource locations constraint. It can use the location property of a resource to identify where it is deployed and maintained by the service. For data-containing resources of some Google Cloud services, this property also reflects the location where data is stored. This constraint allows us to define the allowed Google Cloud locations where the resources for supported services in the hierarchy can be created. These policies should not be violated by individual resources if the restrictions are enforced with important business constraints in mind. Hence it is recommended that all instances are configured to comply with location restriction Organization policies.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1535"
        ]
    },
    {
        "unique_identifier": "99840038",
        "description": [
            {
                "field_data": "Location restriction Organization policies are not enforced retroactively on already existing resources. This means that already existing resources that violate these policies will not be deleted/altered since there might be operational pitfalls as a result of taking such an action.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control can have major operational repercussion, and should be carried out only if crucial services are not being impacted critically.",
                "field_type": "impact"
            },
            {
                "field_data": "Organization policies can be set up to create restrictions on resources being assigned to certain regions. It limit the physical location of a new resource with the Organization Policy Service resource locations constraint. It can use the location property of a resource to identify where it is deployed and maintained by the service. For data-containing resources of some Google Cloud services, this property also reflects the location where data is stored. This constraint allows us to define the allowed Google Cloud locations where the resources for supported services in the hierarchy can be created. These policies should not be violated by individual resources if the restrictions are enforced with important business constraints in mind. Hence it is recommended that all instances are configured to comply with location restriction Organization policies.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1535"
        ]
    },
    {
        "unique_identifier": "99840038",
        "description": [
            {
                "field_data": "Location restriction Organization policies are not enforced retroactively on already existing resources. This means that already existing resources that violate these policies will not be deleted/altered since there might be operational pitfalls as a result of taking such an action.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control can have major operational repercussion, and should be carried out only if crucial services are not being impacted critically.",
                "field_type": "impact"
            },
            {
                "field_data": "Organization policies can be set up to create restrictions on resources being assigned to certain regions. It limit the physical location of a new resource with the Organization Policy Service resource locations constraint. It can use the location property of a resource to identify where it is deployed and maintained by the service. For data-containing resources of some Google Cloud services, this property also reflects the location where data is stored. This constraint allows us to define the allowed Google Cloud locations where the resources for supported services in the hierarchy can be created. These policies should not be violated by individual resources if the restrictions are enforced with important business constraints in mind. Hence it is recommended that all instances are configured to comply with location restriction Organization policies.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1535"
        ]
    },
    {
        "unique_identifier": "99840038",
        "description": [
            {
                "field_data": "Location restriction Organization policies are not enforced retroactively on already existing resources. This means that already existing resources that violate these policies will not be deleted/altered since there might be operational pitfalls as a result of taking such an action.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control can have major operational repercussion, and should be carried out only if crucial services are not being impacted critically.",
                "field_type": "impact"
            },
            {
                "field_data": "Organization policies can be set up to create restrictions on resources being assigned to certain regions. It limit the physical location of a new resource with the Organization Policy Service resource locations constraint. It can use the location property of a resource to identify where it is deployed and maintained by the service. For data-containing resources of some Google Cloud services, this property also reflects the location where data is stored. This constraint allows us to define the allowed Google Cloud locations where the resources for supported services in the hierarchy can be created. These policies should not be violated by individual resources if the restrictions are enforced with important business constraints in mind. Hence it is recommended that all instances are configured to comply with location restriction Organization policies.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1535"
        ]
    },
    {
        "unique_identifier": "99840038",
        "description": [
            {
                "field_data": "Location restriction Organization policies are not enforced retroactively on already existing resources. This means that already existing resources that violate these policies will not be deleted/altered since there might be operational pitfalls as a result of taking such an action.",
                "field_type": "businessDescription"
            },
            {
                "field_data": "The remediation of this control can have major operational repercussion, and should be carried out only if crucial services are not being impacted critically.",
                "field_type": "impact"
            },
            {
                "field_data": "Organization policies can be set up to create restrictions on resources being assigned to certain regions. It limit the physical location of a new resource with the Organization Policy Service resource locations constraint. It can use the location property of a resource to identify where it is deployed and maintained by the service. For data-containing resources of some Google Cloud services, this property also reflects the location where data is stored. This constraint allows us to define the allowed Google Cloud locations where the resources for supported services in the hierarchy can be created. These policies should not be violated by individual resources if the restrictions are enforced with important business constraints in mind. Hence it is recommended that all instances are configured to comply with location restriction Organization policies.",
                "field_type": "technicalDescription"
            }
        ],
        "techniqueMapping": [
            "T1535"
        ]
    }
]